{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5101d226-325d-407a-82d7-5b221da9ce69",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"><img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53007a3d-38ff-4cd1-859b-0ced1e8500cd",
   "metadata": {},
   "source": [
    "## Assessment: Building a Real-Time Video AI Application ##\n",
    "In this notebook, you will utilize what you've learned in this course to complete an assessment. The assessment has been divided into a couple of steps - each of which will generate a text file for grading purposes. You will be graded based on the following rubric. Note that this coding portion does not give partial credit - it shows up as either 0 or 60 points. Earning 50 points or more will award you the full 60 points, while earning less than 50 points will award you 0 points for the coding portion. \n",
    "<table border=\"1\" class=\"dataframe\" align='left'>  <thead>    <tr style=\"text-align: right;\">      <th>Step</th>      <th># of &lt;FIXME&gt;</th>      <th>Points</th>    </tr>  </thead>  <tbody>    <tr>      <td>0. The Problem</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <td>1. Understanding the Input Video</td>      <td>5</td>      <td>10</td>    </tr>    <tr>      <td>2. Brainstorm AI Inference and Download a Pre-Trained Model</td>      <td>2</td>      <td>10</td>    </tr>    <tr>      <td>3. Edit the Inference Configuration File</td>      <td>10</td>      <td>10</td>    </tr>    <tr>      <td>4. Build and Run DeepStream Pipeline</td>      <td>20</td>      <td>20</td>    </tr>    <tr>      <td>5. Analyze the Results</td>      <td>1</td>      <td>10</td>    </tr>    <tr>      <td>BONUS. Visualize Frames</td>      <td>0</td>      <td>0</td>    </tr>  </tbody></table>\n",
    "\n",
    "<p><img src='images/iva_framework.png' width=600></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea28a7a-3536-4c75-8c84-5978f49db9a6",
   "metadata": {},
   "source": [
    "### Step 0: The Problem ###\n",
    "You are a developer for an automobile fleet management company. You have recently installed dashboard cameras on all of the vehicles and are ready to implement AI to analyze the fleet's driving behavior. One of the issues you've noticed with the fleet is [tailgating](https://en.wikipedia.org/wiki/Tailgating), which occurs when the vehicle drives behind another vehicle without leaving sufficient distance to stop without causing a collision if the vehicle in front stops suddenly. You've decied to build a DeepStream application that will help monitor this behavior. At this point, you want to be able to log occurences of tailgating so you can understand the frequency. Note that while the input video sources are static files, the pipeline can easily be modified to consume videos in real-time. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f1c9bd-488a-4b54-bbc0-80ab4ecd5c4e",
   "metadata": {},
   "source": [
    "**Instructions**: <br>\n",
    "0.1 Execute the cell to set the target video as an environment variable. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8f79d8c-9bc3-4f2b-929b-3baab61cbd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.1\n",
    "# DO NOT CHANGE THIS CELL\n",
    "import os\n",
    "os.environ['TARGET_VIDEO_PATH']='data/assessment_stream.h264'\n",
    "os.environ['TARGET_VIDEO_PATH_MP4']='data/assessment_stream.mp4'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d18bdd-6ee6-4241-aa2b-d057bd04309d",
   "metadata": {},
   "source": [
    "### Step 1: Understanding the Input Video ###\n",
    "The first step is to understand the properties of the input videos before we can design a system to digest them. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42feee71-f5d3-4f15-a120-5aaf12724b70",
   "metadata": {},
   "source": [
    "Use the `ffprobe` ([see documentation if needed](https://ffmpeg.org/ffprobe.html)) command line utility to obtain the `height`, `width`, and `frame rate` of the input video. We're also using the `-hide_banner` option to minimize the text output. \n",
    "\n",
    "**Instructions**: <br>\n",
    "1.1 Execute the cell to preview the video. <br>\n",
    "1.2 Execute the cell to gather information from input video stream. <br>\n",
    "1.3 Modify the `<FIXME>`s _only_ to the correct values and execute the cell to mark your answer. _You can execute this cell multiple times until satisfactory_. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4976ef4-5a16-4106-8454-48c07cfad8d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"data/assessment_stream.mp4\" controls  width=\"720\" >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1.1\n",
    "# DO NOT CHANGE THIS CELL\n",
    "from IPython.display import Video\n",
    "Video(os.environ['TARGET_VIDEO_PATH_MP4'], width=720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83672ee2-3e0f-47b1-bac3-f22df24669e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input #0, h264, from 'data/assessment_stream.h264':\n",
      "  Duration: N/A, bitrate: N/A\n",
      "    Stream #0:0: Video: h264 (High), yuv420p(progressive), 1280x720, 59.94 fps, 59.94 tbr, 1200k tbn, 119.88 tbc\n"
     ]
    }
   ],
   "source": [
    "# 1.2\n",
    "# DO NOT CHANGE THIS CELL\n",
    "!ffprobe -i $TARGET_VIDEO_PATH \\\n",
    "         -hide_banner \\\n",
    "         2>&1| tee my_assessment/video_profile.txt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "368d5c7b-7798-4920-800f-608d3752d2ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3\n",
    "FRAME_RATE=59.94\n",
    "FRAME_HEIGHT=720\n",
    "FRAME_WIDTH=1280\n",
    "FRAME_CODEC='h264'\n",
    "FRAME_COLOR_FORMAT='yuv420p'\n",
    "\n",
    "# DO NOT CHANGE BELOW\n",
    "Answer=f\"\"\"\\\n",
    "FRAME RATE: {round(FRAME_RATE)} FPS \\\n",
    "HEIGHT: {FRAME_HEIGHT} \\\n",
    "WIDTH: {FRAME_WIDTH} \\\n",
    "FRAME_CODEC: {FRAME_CODEC} \\\n",
    "FRAME_COLOR_FORMAT: {FRAME_COLOR_FORMAT} \\\n",
    "\"\"\"\n",
    "\n",
    "!echo $Answer > my_assessment/answer_1.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1998b0e1-2bb8-4922-af6a-710f2e47f9df",
   "metadata": {},
   "source": [
    "### Step 2: Brainstorm AI Inference and Download a Pre-Trained Model ###\n",
    "The next step is to brain storm the AI inference needed to achieve the objective. For this application, we need to detect cars in the frame and identify cases when the bounding box crosses below a threshold (illustrated below). \n",
    "\n",
    "<p><img src='images/tailgating_logic.png' width=720></p>\n",
    "\n",
    "Fortunately, there is a [DashCamNet](https://catalog.ngc.nvidia.com/orgs/nvidia/models/tlt_dashcamnet) purpose-built object detection model that has been trained on similar data as our video. We can use the [NGC CLI](https://ngc.nvidia.com/setup/installers/cli) to download the [DashCamNet](https://catalog.ngc.nvidia.com/orgs/nvidia/models/tlt_dashcamnet) model for our application"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56ba02d6-91d7-467a-8063-4b161beda2cf",
   "metadata": {},
   "source": [
    "**Instructions**: <br>\n",
    "2.1 Execute the cell to install the NGC CLI. <br>\n",
    "2.2 Execute the cell to use the `ngc registry mode list` command that lists all available models. We use the `--column name`, `--column repository`, and `--column application` options to display only the relevant columns. Afterwards, review the model card for [DashCamNet](https://catalog.ngc.nvidia.com/orgs/nvidia/models/tlt_dashcamnet) and confirm that the model is fit for purpose. <br>\n",
    "2.3 Update the `<FIXME>`s _only_ and execute the cell to download the [DashCamNet](https://catalog.ngc.nvidia.com/orgs/nvidia/models/tlt_dashcamnet) model. The output of the command will generate a text file for grading purposes. _You can execute this cell multiple times until satisfactory_. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37f0c649-280e-4ad9-a45f-4125c36afa13",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CLI=ngccli_cat_linux.zip\n",
      "--2022-12-23 06:32:15--  https://ngc.nvidia.com/downloads/ngccli_cat_linux.zip\n",
      "Resolving ngc.nvidia.com (ngc.nvidia.com)... 18.165.83.59, 18.165.83.53, 18.165.83.119, ...\n",
      "Connecting to ngc.nvidia.com (ngc.nvidia.com)|18.165.83.59|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 39230389 (37M) [application/zip]\n",
      "Saving to: ‘/dli/task/ngc_assets/ngccli/ngccli_cat_linux.zip’\n",
      "\n",
      "ngccli_cat_linux.zi 100%[===================>]  37.41M  --.-KB/s    in 0.1s    \n",
      "\n",
      "2022-12-23 06:32:15 (280 MB/s) - ‘/dli/task/ngc_assets/ngccli/ngccli_cat_linux.zip’ saved [39230389/39230389]\n",
      "\n",
      "Archive:  /dli/task/ngc_assets/ngccli/ngccli_cat_linux.zip\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/base_library.zip  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/jsonpickle-2.0.0.dist-info/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/jsonpickle-2.0.0.dist-info/INSTALLER  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/jsonpickle-2.0.0.dist-info/METADATA  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/jsonpickle-2.0.0.dist-info/direct_url.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/jsonpickle-2.0.0.dist-info/RECORD  \n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/jsonpickle-2.0.0.dist-info/top_level.txt  \n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/jsonpickle-2.0.0.dist-info/REQUESTED  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/jsonpickle-2.0.0.dist-info/LICENSE  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/jsonpickle-2.0.0.dist-info/WHEEL  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/importlib_metadata-5.0.0.dist-info/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/importlib_metadata-5.0.0.dist-info/INSTALLER  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/importlib_metadata-5.0.0.dist-info/METADATA  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/importlib_metadata-5.0.0.dist-info/direct_url.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/importlib_metadata-5.0.0.dist-info/RECORD  \n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/importlib_metadata-5.0.0.dist-info/top_level.txt  \n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/importlib_metadata-5.0.0.dist-info/REQUESTED  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/importlib_metadata-5.0.0.dist-info/LICENSE  \n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/importlib_metadata-5.0.0.dist-info/WHEEL  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/libz.so.1  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/cryptography/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/cryptography/hazmat/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/cryptography/hazmat/bindings/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/cryptography/hazmat/bindings/_openssl.abi3.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/cryptography/hazmat/bindings/_rust.abi3.so  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/aiohttp/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/aiohttp/_http_parser.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/aiohttp/_http_writer.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/aiohttp/_helpers.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/aiohttp/_websocket.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/libkeyutils.so.1  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/libgssapi_krb5.so.2  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/libfreebl3.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/libpython3.9.so.1.0  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/libgcc_s.so.1  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/certifi/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/certifi/cacert.pem  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/libffi-9c61262e.so.8.1.0  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/libpcre.so.1  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/libcrypto.so.10  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/libkrb5.so.3  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/google_api_core-2.2.2.dist-info/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/google_api_core-2.2.2.dist-info/INSTALLER  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/google_api_core-2.2.2.dist-info/METADATA  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/google_api_core-2.2.2.dist-info/direct_url.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/google_api_core-2.2.2.dist-info/RECORD  \n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/google_api_core-2.2.2.dist-info/top_level.txt  \n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/google_api_core-2.2.2.dist-info/REQUESTED  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/google_api_core-2.2.2.dist-info/LICENSE  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/google_api_core-2.2.2.dist-info/WHEEL  \n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/google_api_core-2.2.2.dist-info/namespace_packages.txt  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/grpc/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/grpc/_cython/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/grpc/_cython/cygrpc.cpython-39-x86_64-linux-gnu.so  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/grpc/_cython/_credentials/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/grpc/_cython/_credentials/roots.pem  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/cryptography-36.0.1.dist-info/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/cryptography-36.0.1.dist-info/INSTALLER  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/cryptography-36.0.1.dist-info/METADATA  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/cryptography-36.0.1.dist-info/RECORD  \n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/cryptography-36.0.1.dist-info/top_level.txt  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/cryptography-36.0.1.dist-info/LICENSE.APACHE  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/cryptography-36.0.1.dist-info/LICENSE.PSF  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/cryptography-36.0.1.dist-info/LICENSE  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/cryptography-36.0.1.dist-info/WHEEL  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/cryptography-36.0.1.dist-info/LICENSE.BSD  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/psutil/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/psutil/_psutil_linux.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/psutil/_psutil_posix.cpython-39-x86_64-linux-gnu.so  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_json.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_struct.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/binascii.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/unicodedata.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_codecs_hk.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_codecs_iso2022.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/pyexpat.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_sha512.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_queue.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_heapq.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_socket.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_ssl.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/fcntl.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_posixshmem.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_opcode.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/math.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_sha256.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_csv.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_ctypes.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/mmap.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/select.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_posixsubprocess.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_asyncio.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/array.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_multibytecodec.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_codecs_tw.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/zlib.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_multiprocessing.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/termios.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/resource.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_random.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_contextvars.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_pickle.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_statistics.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_sha1.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_codecs_kr.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_bisect.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_sha3.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_blake2.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_elementtree.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_codecs_cn.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_decimal.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_md5.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_datetime.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_hashlib.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/_codecs_jp.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/lib-dynload/grp.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/main.so  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/thrift/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/thrift/protocol/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/thrift/protocol/fastbinary.cpython-39-x86_64-linux-gnu.so  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/yarl/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/yarl/_quoting_c.cpython-39-x86_64-linux-gnu.so  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/google/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/google/protobuf/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/google/protobuf/pyext/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/google/protobuf/pyext/_message.cpython-39-x86_64-linux-gnu.so  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/google/protobuf/internal/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/google/protobuf/internal/_api_implementation.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/libkrb5support.so.0  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/libcom_err.so.2  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/frozenlist/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/frozenlist/_frozenlist.cpython-39-x86_64-linux-gnu.so  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/libselinux.so.1  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/ngc  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/examples/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/examples/s3.rst  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/examples/cloudfront.rst  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/sqs/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/sqs/2012-11-05/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/sqs/2012-11-05/resources-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/sns/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/sns/2010-03-31/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/sns/2010-03-31/resources-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/ec2/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2015-04-15/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2015-04-15/resources-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2016-09-15/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2016-09-15/resources-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2016-04-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2016-04-01/resources-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2016-11-15/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2016-11-15/resources-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2015-03-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2015-03-01/resources-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2015-10-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2015-10-01/resources-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2014-10-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/ec2/2014-10-01/resources-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/cloudformation/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/cloudformation/2010-05-15/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/cloudformation/2010-05-15/resources-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/s3/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/s3/2006-03-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/s3/2006-03-01/resources-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/glacier/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/glacier/2012-06-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/glacier/2012-06-01/resources-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/iam/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/iam/2010-05-08/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/iam/2010-05-08/resources-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/cloudwatch/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/cloudwatch/2010-08-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/cloudwatch/2010-08-01/resources-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/dynamodb/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/dynamodb/2012-08-10/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/dynamodb/2012-08-10/resources-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/opsworks/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/opsworks/2013-02-18/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/boto3/data/opsworks/2013-02-18/resources-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/_cffi_backend.cpython-39-x86_64-linux-gnu.so  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/cacert.pem  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resiliencehub/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resiliencehub/2020-04-30/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resiliencehub/2020-04-30/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resiliencehub/2020-04-30/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pi/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pi/2018-02-27/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pi/2018-02-27/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pi/2018-02-27/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pi/2018-02-27/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mobile/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mobile/2017-07-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mobile/2017-07-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mobile/2017-07-01/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mobile/2017-07-01/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/autoscaling/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/autoscaling/2011-01-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/autoscaling/2011-01-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/autoscaling/2011-01-01/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/autoscaling/2011-01-01/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lightsail/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lightsail/2016-11-28/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lightsail/2016-11-28/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lightsail/2016-11-28/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lightsail/2016-11-28/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sqs/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sqs/2012-11-05/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sqs/2012-11-05/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sqs/2012-11-05/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sqs/2012-11-05/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/discovery/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/discovery/2015-11-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/discovery/2015-11-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/discovery/2015-11-01/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/discovery/2015-11-01/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sns/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sns/2010-03-31/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sns/2010-03-31/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sns/2010-03-31/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sns/2010-03-31/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeguruprofiler/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeguruprofiler/2019-07-18/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeguruprofiler/2019-07-18/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeguruprofiler/2019-07-18/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ce/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ce/2017-10-25/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ce/2017-10-25/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ce/2017-10-25/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ce/2017-10-25/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediaconvert/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediaconvert/2017-08-29/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediaconvert/2017-08-29/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediaconvert/2017-08-29/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elb/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elb/2012-06-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elb/2012-06-01/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elb/2012-06-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elb/2012-06-01/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elb/2012-06-01/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudhsmv2/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudhsmv2/2017-04-28/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudhsmv2/2017-04-28/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudhsmv2/2017-04-28/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudhsmv2/2017-04-28/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/detective/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/detective/2018-10-26/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/detective/2018-10-26/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/detective/2018-10-26/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/signer/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/signer/2017-08-25/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/signer/2017-08-25/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/signer/2017-08-25/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/signer/2017-08-25/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/signer/2017-08-25/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kafkaconnect/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kafkaconnect/2021-09-14/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kafkaconnect/2021-09-14/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kafkaconnect/2021-09-14/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotfleethub/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotfleethub/2020-11-03/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotfleethub/2020-11-03/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotfleethub/2020-11-03/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-archived-media/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-archived-media/2017-09-30/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-archived-media/2017-09-30/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-archived-media/2017-09-30/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-archived-media/2017-09-30/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/secretsmanager/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/secretsmanager/2017-10-17/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/secretsmanager/2017-10-17/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/secretsmanager/2017-10-17/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/secretsmanager/2017-10-17/service-2.sdk-extras.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/secretsmanager/2017-10-17/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/network-firewall/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/network-firewall/2020-11-12/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/network-firewall/2020-11-12/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/network-firewall/2020-11-12/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotsitewise/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotsitewise/2019-12-02/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotsitewise/2019-12-02/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotsitewise/2019-12-02/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotsitewise/2019-12-02/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apigatewayv2/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apigatewayv2/2018-11-29/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apigatewayv2/2018-11-29/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apigatewayv2/2018-11-29/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/panorama/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/panorama/2019-07-24/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/panorama/2019-07-24/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/panorama/2019-07-24/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediaconnect/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediaconnect/2018-11-14/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediaconnect/2018-11-14/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediaconnect/2018-11-14/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediaconnect/2018-11-14/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm-incidents/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm-incidents/2018-05-10/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm-incidents/2018-05-10/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm-incidents/2018-05-10/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm-incidents/2018-05-10/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/identitystore/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/identitystore/2020-06-15/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/identitystore/2020-06-15/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/identitystore/2020-06-15/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mturk/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mturk/2017-01-17/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mturk/2017-01-17/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mturk/2017-01-17/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mturk/2017-01-17/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/devicefarm/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/devicefarm/2015-06-23/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/devicefarm/2015-06-23/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/devicefarm/2015-06-23/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/devicefarm/2015-06-23/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/guardduty/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/guardduty/2017-11-28/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/guardduty/2017-11-28/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/guardduty/2017-11-28/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/transfer/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/transfer/2018-11-05/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/transfer/2018-11-05/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/transfer/2018-11-05/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/braket/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/braket/2019-09-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/braket/2019-09-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/braket/2019-09-01/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/shield/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/shield/2016-06-02/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/shield/2016-06-02/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/shield/2016-06-02/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/shield/2016-06-02/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/outposts/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/outposts/2019-12-03/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/outposts/2019-12-03/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/outposts/2019-12-03/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm-contacts/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm-contacts/2021-05-03/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm-contacts/2021-05-03/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm-contacts/2021-05-03/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/managedblockchain/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/managedblockchain/2018-09-24/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/managedblockchain/2018-09-24/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/managedblockchain/2018-09-24/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/schemas/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/schemas/2019-12-02/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/schemas/2019-12-02/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/schemas/2019-12-02/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/schemas/2019-12-02/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/wisdom/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/wisdom/2020-10-19/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/wisdom/2020-10-19/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/wisdom/2020-10-19/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/wellarchitected/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/wellarchitected/2020-03-31/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/wellarchitected/2020-03-31/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/wellarchitected/2020-03-31/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/neptune/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/neptune/2014-10-31/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/neptune/2014-10-31/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/neptune/2014-10-31/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/neptune/2014-10-31/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/neptune/2014-10-31/service-2.sdk-extras.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/neptune/2014-10-31/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotsecuretunneling/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotsecuretunneling/2018-10-05/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotsecuretunneling/2018-10-05/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotsecuretunneling/2018-10-05/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesisvideo/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesisvideo/2017-09-30/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesisvideo/2017-09-30/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesisvideo/2017-09-30/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesisvideo/2017-09-30/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-a2i-runtime/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-a2i-runtime/2019-11-07/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-a2i-runtime/2019-11-07/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-a2i-runtime/2019-11-07/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot-jobs-data/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot-jobs-data/2017-09-29/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot-jobs-data/2017-09-29/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot-jobs-data/2017-09-29/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot-jobs-data/2017-09-29/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dynamodbstreams/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dynamodbstreams/2012-08-10/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dynamodbstreams/2012-08-10/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dynamodbstreams/2012-08-10/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dynamodbstreams/2012-08-10/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ds/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ds/2015-04-16/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ds/2015-04-16/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ds/2015-04-16/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ds/2015-04-16/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codestar/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codestar/2017-04-19/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codestar/2017-04-19/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codestar/2017-04-19/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codestar/2017-04-19/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/imagebuilder/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/imagebuilder/2019-12-02/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/imagebuilder/2019-12-02/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/imagebuilder/2019-12-02/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediapackage/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediapackage/2017-10-12/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediapackage/2017-10-12/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediapackage/2017-10-12/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apigatewaymanagementapi/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apigatewaymanagementapi/2018-11-29/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apigatewaymanagementapi/2018-11-29/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apigatewaymanagementapi/2018-11-29/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/serverlessrepo/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/serverlessrepo/2017-09-08/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/serverlessrepo/2017-09-08/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/serverlessrepo/2017-09-08/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-messaging/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-messaging/2021-05-15/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-messaging/2021-05-15/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-messaging/2021-05-15/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/polly/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/polly/2016-06-10/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/polly/2016-06-10/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/polly/2016-06-10/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/polly/2016-06-10/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elbv2/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elbv2/2015-12-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elbv2/2015-12-01/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elbv2/2015-12-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elbv2/2015-12-01/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elbv2/2015-12-01/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-04-15/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-04-15/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-04-15/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-04-15/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-09-15/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-09-15/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-09-15/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-09-15/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-09-15/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-04-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-04-01/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-04-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-04-01/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-11-15/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-11-15/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-11-15/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-11-15/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2016-11-15/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-03-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-03-01/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-03-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-03-01/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2014-09-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2014-09-01/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2014-09-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2014-09-01/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-10-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-10-01/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-10-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2015-10-01/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2014-10-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2014-10-01/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2014-10-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2/2014-10-01/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot1click-devices/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot1click-devices/2018-05-14/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot1click-devices/2018-05-14/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot1click-devices/2018-05-14/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/account/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/account/2021-02-01/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/account/2021-02-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/account/2021-02-01/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/importexport/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/importexport/2010-06-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/importexport/2010-06-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/importexport/2010-06-01/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediastore-data/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediastore-data/2017-09-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediastore-data/2017-09-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediastore-data/2017-09-01/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediastore-data/2017-09-01/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lambda/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lambda/2014-11-11/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lambda/2014-11-11/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lambda/2015-03-31/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lambda/2015-03-31/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lambda/2015-03-31/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lambda/2015-03-31/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lambda/2015-03-31/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kms/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kms/2014-11-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kms/2014-11-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kms/2014-11-01/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kms/2014-11-01/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplacecommerceanalytics/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplacecommerceanalytics/2015-07-01/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplacecommerceanalytics/2015-07-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplacecommerceanalytics/2015-07-01/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplacecommerceanalytics/2015-07-01/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/timestream-query/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/timestream-query/2018-11-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/timestream-query/2018-11-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/timestream-query/2018-11-01/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/timestream-write/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/timestream-write/2018-11-01/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/timestream-write/2018-11-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/timestream-write/2018-11-01/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workspaces/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workspaces/2015-04-08/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workspaces/2015-04-08/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workspaces/2015-04-08/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workspaces/2015-04-08/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/migrationhub-config/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/migrationhub-config/2019-06-30/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/migrationhub-config/2019-06-30/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/migrationhub-config/2019-06-30/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53/2013-04-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53/2013-04-01/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53/2013-04-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53/2013-04-01/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53/2013-04-01/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3outposts/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3outposts/2017-07-25/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3outposts/2017-07-25/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3outposts/2017-07-25/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotevents-data/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotevents-data/2018-10-23/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotevents-data/2018-10-23/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotevents-data/2018-10-23/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codecommit/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codecommit/2015-04-13/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codecommit/2015-04-13/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codecommit/2015-04-13/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codecommit/2015-04-13/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-signaling/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-signaling/2019-12-04/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-signaling/2019-12-04/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-signaling/2019-12-04/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesisanalytics/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesisanalytics/2015-08-14/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesisanalytics/2015-08-14/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesisanalytics/2015-08-14/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesisanalytics/2015-08-14/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/location/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/location/2020-11-19/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/location/2020-11-19/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/location/2020-11-19/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/_retry.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/securityhub/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/securityhub/2018-10-26/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/securityhub/2018-10-26/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/securityhub/2018-10-26/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/synthetics/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/synthetics/2017-10-11/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/synthetics/2017-10-11/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/synthetics/2017-10-11/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/redshift-data/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/redshift-data/2019-12-20/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/redshift-data/2019-12-20/paginators-1.sdk-extras.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/redshift-data/2019-12-20/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/redshift-data/2019-12-20/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/athena/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/athena/2017-05-18/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/athena/2017-05-18/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/athena/2017-05-18/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/athena/2017-05-18/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/grafana/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/grafana/2020-08-18/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/grafana/2020-08-18/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/grafana/2020-08-18/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mq/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mq/2017-11-27/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mq/2017-11-27/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mq/2017-11-27/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/autoscaling-plans/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/autoscaling-plans/2018-01-06/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/autoscaling-plans/2018-01-06/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/autoscaling-plans/2018-01-06/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/autoscaling-plans/2018-01-06/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/storagegateway/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/storagegateway/2013-06-30/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/storagegateway/2013-06-30/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/storagegateway/2013-06-30/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/storagegateway/2013-06-30/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mwaa/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mwaa/2020-07-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mwaa/2020-07-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mwaa/2020-07-01/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/xray/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/xray/2016-04-12/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/xray/2016-04-12/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/xray/2016-04-12/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/xray/2016-04-12/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/memorydb/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/memorydb/2021-01-01/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/memorydb/2021-01-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/memorydb/2021-01-01/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint-sms-voice/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint-sms-voice/2018-09-05/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint-sms-voice/2018-09-05/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/translate/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/translate/2017-07-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/translate/2017-07-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/translate/2017-07-01/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/translate/2017-07-01/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudcontrol/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudcontrol/2021-09-30/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudcontrol/2021-09-30/waiters-2.json  \n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudcontrol/2021-09-30/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudcontrol/2021-09-30/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/backup/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/backup/2018-11-15/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/backup/2018-11-15/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/backup/2018-11-15/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elastictranscoder/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elastictranscoder/2012-09-25/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elastictranscoder/2012-09-25/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elastictranscoder/2012-09-25/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elastictranscoder/2012-09-25/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elastictranscoder/2012-09-25/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/alexaforbusiness/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/alexaforbusiness/2017-11-09/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/alexaforbusiness/2017-11-09/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/alexaforbusiness/2017-11-09/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/alexaforbusiness/2017-11-09/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pricing/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pricing/2017-10-15/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pricing/2017-10-15/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pricing/2017-10-15/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pricing/2017-10-15/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mgn/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mgn/2020-02-26/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mgn/2020-02-26/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mgn/2020-02-26/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cognito-sync/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cognito-sync/2014-06-30/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cognito-sync/2014-06-30/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cognito-sync/2014-06-30/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/efs/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/efs/2015-02-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/efs/2015-02-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/efs/2015-02-01/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/efs/2015-02-01/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dlm/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dlm/2018-01-12/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dlm/2018-01-12/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dlm/2018-01-12/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dlm/2018-01-12/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/finspace-data/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/finspace-data/2020-07-13/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/finspace-data/2020-07-13/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/finspace-data/2020-07-13/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workmailmessageflow/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workmailmessageflow/2019-05-01/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workmailmessageflow/2019-05-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workmailmessageflow/2019-05-01/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotevents/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotevents/2018-07-27/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotevents/2018-07-27/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotevents/2018-07-27/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/auditmanager/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/auditmanager/2017-07-25/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/auditmanager/2017-07-25/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/auditmanager/2017-07-25/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/forecastquery/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/forecastquery/2018-06-26/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/forecastquery/2018-06-26/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/forecastquery/2018-06-26/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sms-voice/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sms-voice/2018-09-05/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sms-voice/2018-09-05/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rds-data/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rds-data/2018-08-01/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rds-data/2018-08-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rds-data/2018-08-01/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotthingsgraph/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotthingsgraph/2018-09-06/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotthingsgraph/2018-09-06/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotthingsgraph/2018-09-06/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot/2015-05-28/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot/2015-05-28/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot/2015-05-28/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot/2015-05-28/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-edge/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-edge/2020-09-23/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-edge/2020-09-23/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-edge/2020-09-23/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/savingsplans/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/savingsplans/2019-06-28/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/savingsplans/2019-06-28/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/savingsplans/2019-06-28/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/nimble/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/nimble/2020-08-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/nimble/2020-08-01/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/nimble/2020-08-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/nimble/2020-08-01/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/meteringmarketplace/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/meteringmarketplace/2016-01-14/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/meteringmarketplace/2016-01-14/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/meteringmarketplace/2016-01-14/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/meteringmarketplace/2016-01-14/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sts/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sts/2011-06-15/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sts/2011-06-15/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sts/2011-06-15/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sts/2011-06-15/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codestar-notifications/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codestar-notifications/2019-10-15/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codestar-notifications/2019-10-15/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codestar-notifications/2019-10-15/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kafka/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kafka/2018-11-14/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kafka/2018-11-14/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kafka/2018-11-14/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudformation/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudformation/2010-05-15/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudformation/2010-05-15/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudformation/2010-05-15/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudformation/2010-05-15/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudformation/2010-05-15/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lex-runtime/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lex-runtime/2016-11-28/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lex-runtime/2016-11-28/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lex-runtime/2016-11-28/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lex-runtime/2016-11-28/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/voice-id/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/voice-id/2021-09-27/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/voice-id/2021-09-27/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/voice-id/2021-09-27/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/worklink/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/worklink/2018-09-25/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/worklink/2018-09-25/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/worklink/2018-09-25/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/datapipeline/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/datapipeline/2012-10-29/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/datapipeline/2012-10-29/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/datapipeline/2012-10-29/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediatailor/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediatailor/2018-04-23/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediatailor/2018-04-23/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediatailor/2018-04-23/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mgh/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mgh/2017-05-31/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mgh/2017-05-31/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mgh/2017-05-31/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mgh/2017-05-31/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/amplifybackend/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/amplifybackend/2020-08-11/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/amplifybackend/2020-08-11/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/amplifybackend/2020-08-11/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-runtime/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-runtime/2017-05-13/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-runtime/2017-05-13/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-runtime/2017-05-13/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-runtime/2017-05-13/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime/2018-05-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime/2018-05-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime/2018-05-01/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/batch/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/batch/2016-08-10/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/batch/2016-08-10/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/batch/2016-08-10/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/batch/2016-08-10/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appmesh/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appmesh/2018-10-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appmesh/2018-10-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appmesh/2018-10-01/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appmesh/2019-01-25/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appmesh/2019-01-25/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appmesh/2019-01-25/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-readiness/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-readiness/2019-12-02/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-readiness/2019-12-02/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-readiness/2019-12-02/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cognito-identity/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cognito-identity/2014-06-30/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cognito-identity/2014-06-30/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cognito-identity/2014-06-30/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cognito-identity/2014-06-30/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/support/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/support/2013-04-15/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/support/2013-04-15/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/support/2013-04-15/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/support/2013-04-15/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/macie/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/macie/2017-12-19/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/macie/2017-12-19/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/macie/2017-12-19/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/macie/2017-12-19/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ses/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ses/2010-12-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ses/2010-12-01/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ses/2010-12-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ses/2010-12-01/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ses/2010-12-01/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/forecast/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/forecast/2018-06-26/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/forecast/2018-06-26/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/forecast/2018-06-26/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeguru-reviewer/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeguru-reviewer/2019-09-19/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeguru-reviewer/2019-09-19/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeguru-reviewer/2019-09-19/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeguru-reviewer/2019-09-19/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/healthlake/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/healthlake/2017-07-01/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/healthlake/2017-07-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/healthlake/2017-07-01/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/macie2/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/macie2/2020-01-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/macie2/2020-01-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/macie2/2020-01-01/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ecr/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ecr/2015-09-21/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ecr/2015-09-21/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ecr/2015-09-21/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ecr/2015-09-21/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ecr/2015-09-21/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appsync/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appsync/2017-07-25/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appsync/2017-07-25/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appsync/2017-07-25/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appsync/2017-07-25/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/snow-device-management/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/snow-device-management/2021-08-04/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/snow-device-management/2021-08-04/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/snow-device-management/2021-08-04/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/comprehend/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/comprehend/2017-11-27/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/comprehend/2017-11-27/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/comprehend/2017-11-27/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/comprehend/2017-11-27/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apigateway/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apigateway/2015-07-09/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apigateway/2015-07-09/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apigateway/2015-07-09/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apigateway/2015-07-09/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/finspace/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/finspace/2021-03-12/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/finspace/2021-03-12/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/finspace/2021-03-12/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/honeycode/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/honeycode/2020-03-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/honeycode/2020-03-01/paginators-1.sdk-extras.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/honeycode/2020-03-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/honeycode/2020-03-01/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-control-config/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-control-config/2020-11-02/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-control-config/2020-11-02/waiters-2.json  \n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-control-config/2020-11-02/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-control-config/2020-11-02/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/budgets/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/budgets/2016-10-20/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/budgets/2016-10-20/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/budgets/2016-10-20/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/budgets/2016-10-20/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sso-admin/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sso-admin/2020-07-20/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sso-admin/2020-07-20/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sso-admin/2020-07-20/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rds/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rds/2014-09-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rds/2014-09-01/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rds/2014-09-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rds/2014-09-01/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rds/2014-10-31/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rds/2014-10-31/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rds/2014-10-31/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rds/2014-10-31/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rds/2014-10-31/service-2.sdk-extras.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rds/2014-10-31/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/firehose/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/firehose/2015-08-04/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/firehose/2015-08-04/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/firehose/2015-08-04/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/firehose/2015-08-04/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lexv2-runtime/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lexv2-runtime/2020-08-07/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lexv2-runtime/2020-08-07/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lexv2-runtime/2020-08-07/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2-instance-connect/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2-instance-connect/2018-04-02/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2-instance-connect/2018-04-02/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ec2-instance-connect/2018-04-02/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3control/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3control/2018-08-20/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3control/2018-08-20/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3control/2018-08-20/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediastore/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediastore/2017-09-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediastore/2017-09-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediastore/2017-09-01/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediastore/2017-09-01/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/application-autoscaling/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/application-autoscaling/2016-02-06/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/application-autoscaling/2016-02-06/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/application-autoscaling/2016-02-06/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/application-autoscaling/2016-02-06/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/databrew/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/databrew/2017-07-25/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/databrew/2017-07-25/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/databrew/2017-07-25/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sso-oidc/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sso-oidc/2019-06-10/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sso-oidc/2019-06-10/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sso-oidc/2019-06-10/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/proton/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/proton/2020-07-20/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/proton/2020-07-20/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/proton/2020-07-20/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/proton/2020-07-20/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/personalize-events/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/personalize-events/2018-03-22/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/personalize-events/2018-03-22/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/personalize-events/2018-03-22/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/compute-optimizer/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/compute-optimizer/2019-11-01/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/compute-optimizer/2019-11-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/compute-optimizer/2019-11-01/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ram/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ram/2018-01-04/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ram/2018-01-04/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ram/2018-01-04/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appstream/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appstream/2016-12-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appstream/2016-12-01/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appstream/2016-12-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appstream/2016-12-01/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appstream/2016-12-01/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/fis/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/fis/2020-12-01/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/fis/2020-12-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/fis/2020-12-01/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/health/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/health/2016-08-04/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/health/2016-08-04/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/health/2016-08-04/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/health/2016-08-04/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudhsm/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudhsm/2014-05-30/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudhsm/2014-05-30/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudhsm/2014-05-30/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudhsm/2014-05-30/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/service-quotas/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/service-quotas/2019-06-24/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/service-quotas/2019-06-24/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/service-quotas/2019-06-24/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3/2006-03-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3/2006-03-01/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3/2006-03-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3/2006-03-01/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/s3/2006-03-01/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connect-contact-lens/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connect-contact-lens/2020-08-21/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connect-contact-lens/2020-08-21/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connect-contact-lens/2020-08-21/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/acm-pca/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/acm-pca/2017-08-22/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/acm-pca/2017-08-22/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/acm-pca/2017-08-22/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/acm-pca/2017-08-22/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/acm-pca/2017-08-22/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elastic-inference/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elastic-inference/2017-07-25/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elastic-inference/2017-07-25/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elastic-inference/2017-07-25/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotwireless/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotwireless/2020-11-22/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotwireless/2020-11-22/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotwireless/2020-11-22/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53resolver/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53resolver/2018-04-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53resolver/2018-04-01/paginators-1.sdk-extras.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53resolver/2018-04-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53resolver/2018-04-01/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-featurestore-runtime/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-featurestore-runtime/2020-07-01/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-featurestore-runtime/2020-07-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker-featurestore-runtime/2020-07-01/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/robomaker/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/robomaker/2018-06-29/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/robomaker/2018-06-29/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/robomaker/2018-06-29/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/transcribe/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/transcribe/2017-10-26/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/transcribe/2017-10-26/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/transcribe/2017-10-26/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/transcribe/2017-10-26/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/servicediscovery/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/servicediscovery/2017-03-14/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/servicediscovery/2017-03-14/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/servicediscovery/2017-03-14/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/servicediscovery/2017-03-14/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appflow/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appflow/2020-08-23/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appflow/2020-08-23/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appflow/2020-08-23/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/groundstation/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/groundstation/2019-05-23/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/groundstation/2019-05-23/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/groundstation/2019-05-23/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rekognition/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rekognition/2016-06-27/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rekognition/2016-06-27/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rekognition/2016-06-27/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rekognition/2016-06-27/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/rekognition/2016-06-27/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/wafv2/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/wafv2/2019-07-29/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/wafv2/2019-07-29/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/wafv2/2019-07-29/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotdeviceadvisor/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotdeviceadvisor/2020-09-18/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotdeviceadvisor/2020-09-18/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotdeviceadvisor/2020-09-18/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/application-insights/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/application-insights/2018-11-25/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/application-insights/2018-11-25/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/application-insights/2018-11-25/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/quicksight/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/quicksight/2018-04-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/quicksight/2018-04-01/paginators-1.sdk-extras.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/quicksight/2018-04-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/quicksight/2018-04-01/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codedeploy/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codedeploy/2014-10-06/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codedeploy/2014-10-06/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codedeploy/2014-10-06/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codedeploy/2014-10-06/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codedeploy/2014-10-06/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/personalize-runtime/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/personalize-runtime/2018-05-22/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/personalize-runtime/2018-05-22/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/personalize-runtime/2018-05-22/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codepipeline/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codepipeline/2015-07-09/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codepipeline/2015-07-09/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codepipeline/2015-07-09/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codepipeline/2015-07-09/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/greengrassv2/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/greengrassv2/2020-11-30/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/greengrassv2/2020-11-30/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/greengrassv2/2020-11-30/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/clouddirectory/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/clouddirectory/2016-05-10/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/clouddirectory/2016-05-10/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/clouddirectory/2016-05-10/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/clouddirectory/2017-01-11/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/clouddirectory/2017-01-11/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/clouddirectory/2017-01-11/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/clouddirectory/2017-01-11/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-entitlement/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-entitlement/2017-01-11/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-entitlement/2017-01-11/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-entitlement/2017-01-11/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-entitlement/2017-01-11/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot1click-projects/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot1click-projects/2018-05-14/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot1click-projects/2018-05-14/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot1click-projects/2018-05-14/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot1click-projects/2018-05-14/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codebuild/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codebuild/2016-10-06/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codebuild/2016-10-06/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codebuild/2016-10-06/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codebuild/2016-10-06/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/comprehendmedical/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/comprehendmedical/2018-10-30/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/comprehendmedical/2018-10-30/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/comprehendmedical/2018-10-30/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connect/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connect/2017-08-08/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connect/2017-08-08/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connect/2017-08-08/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connect/2017-08-08/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/machinelearning/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/machinelearning/2014-12-12/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/machinelearning/2014-12-12/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/machinelearning/2014-12-12/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/machinelearning/2014-12-12/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/machinelearning/2014-12-12/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudsearchdomain/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudsearchdomain/2013-01-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudsearchdomain/2013-01-01/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudsearchdomain/2013-01-01/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/swf/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/swf/2012-01-25/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/swf/2012-01-25/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/swf/2012-01-25/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/swf/2012-01-25/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/redshift/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/redshift/2012-12-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/redshift/2012-12-01/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/redshift/2012-12-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/redshift/2012-12-01/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/redshift/2012-12-01/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/glacier/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/glacier/2012-06-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/glacier/2012-06-01/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/glacier/2012-06-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/glacier/2012-06-01/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/glacier/2012-06-01/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workmail/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workmail/2017-10-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workmail/2017-10-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workmail/2017-10-01/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workmail/2017-10-01/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cur/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cur/2017-01-06/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cur/2017-01-06/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cur/2017-01-06/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cur/2017-01-06/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/logs/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/logs/2014-03-28/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/logs/2014-03-28/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/logs/2014-03-28/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/logs/2014-03-28/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesisanalyticsv2/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesisanalyticsv2/2018-05-23/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesisanalyticsv2/2018-05-23/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesisanalyticsv2/2018-05-23/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/acm/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/acm/2015-12-08/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/acm/2015-12-08/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/acm/2015-12-08/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/acm/2015-12-08/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/acm/2015-12-08/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/emr-containers/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/emr-containers/2020-10-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/emr-containers/2020-10-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/emr-containers/2020-10-01/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iam/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iam/2010-05-08/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iam/2010-05-08/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iam/2010-05-08/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iam/2010-05-08/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iam/2010-05-08/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sso/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sso/2019-06-10/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sso/2019-06-10/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sso/2019-06-10/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ebs/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ebs/2019-11-02/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ebs/2019-11-02/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ebs/2019-11-02/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/organizations/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/organizations/2016-11-28/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/organizations/2016-11-28/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/organizations/2016-11-28/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/organizations/2016-11-28/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elasticbeanstalk/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elasticbeanstalk/2010-12-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elasticbeanstalk/2010-12-01/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elasticbeanstalk/2010-12-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elasticbeanstalk/2010-12-01/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elasticbeanstalk/2010-12-01/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/events/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/events/2015-10-07/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/events/2015-10-07/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/events/2015-10-07/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/events/2015-10-07/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/events/2014-02-03/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/events/2014-02-03/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/es/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/es/2015-01-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/es/2015-01-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/es/2015-01-01/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/es/2015-01-01/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lakeformation/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lakeformation/2017-03-31/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lakeformation/2017-03-31/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lakeformation/2017-03-31/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/eks/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/eks/2017-11-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/eks/2017-11-01/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/eks/2017-11-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/eks/2017-11-01/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/eks/2017-11-01/service-2.sdk-extras.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/eks/2017-11-01/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workdocs/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workdocs/2016-05-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workdocs/2016-05-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workdocs/2016-05-01/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/workdocs/2016-05-01/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/waf-regional/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/waf-regional/2016-11-28/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/waf-regional/2016-11-28/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/waf-regional/2016-11-28/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/waf-regional/2016-11-28/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudsearch/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudsearch/2011-02-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudsearch/2011-02-01/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudsearch/2013-01-01/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudsearch/2013-01-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudsearch/2013-01-01/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/networkmanager/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/networkmanager/2019-07-05/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/networkmanager/2019-07-05/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/networkmanager/2019-07-05/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/globalaccelerator/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/globalaccelerator/2018-08-08/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/globalaccelerator/2018-08-08/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/globalaccelerator/2018-08-08/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/docdb/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/docdb/2014-10-31/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/docdb/2014-10-31/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/docdb/2014-10-31/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/docdb/2014-10-31/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/docdb/2014-10-31/service-2.sdk-extras.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/gamelift/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/gamelift/2015-10-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/gamelift/2015-10-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/gamelift/2015-10-01/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/gamelift/2015-10-01/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lexv2-models/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lexv2-models/2020-08-07/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lexv2-models/2020-08-07/waiters-2.json  \n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lexv2-models/2020-08-07/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lexv2-models/2020-08-07/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudwatch/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudwatch/2010-08-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudwatch/2010-08-01/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudwatch/2010-08-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudwatch/2010-08-01/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudwatch/2010-08-01/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kendra/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kendra/2019-02-03/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kendra/2019-02-03/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kendra/2019-02-03/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cognito-idp/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cognito-idp/2016-04-18/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cognito-idp/2016-04-18/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cognito-idp/2016-04-18/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cognito-idp/2016-04-18/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/datasync/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/datasync/2018-11-09/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/datasync/2018-11-09/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/datasync/2018-11-09/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/glue/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/glue/2017-03-31/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/glue/2017-03-31/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/glue/2017-03-31/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/glue/2017-03-31/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/fsx/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/fsx/2018-03-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/fsx/2018-03-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/fsx/2018-03-01/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/qldb-session/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/qldb-session/2019-07-11/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/qldb-session/2019-07-11/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/qldb-session/2019-07-11/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint-email/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint-email/2018-07-26/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint-email/2018-07-26/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint-email/2018-07-26/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elasticache/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elasticache/2015-02-02/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elasticache/2015-02-02/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elasticache/2015-02-02/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elasticache/2015-02-02/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elasticache/2015-02-02/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elasticache/2014-09-30/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elasticache/2014-09-30/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elasticache/2014-09-30/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/elasticache/2014-09-30/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sdb/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sdb/2009-04-15/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sdb/2009-04-15/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sdb/2009-04-15/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sms/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sms/2016-10-24/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sms/2016-10-24/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sms/2016-10-24/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sms/2016-10-24/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/license-manager/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/license-manager/2018-08-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/license-manager/2018-08-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/license-manager/2018-08-01/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotanalytics/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotanalytics/2017-11-27/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotanalytics/2017-11-27/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotanalytics/2017-11-27/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iotanalytics/2017-11-27/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/frauddetector/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/frauddetector/2019-11-15/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/frauddetector/2019-11-15/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/frauddetector/2019-11-15/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/textract/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/textract/2018-06-27/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/textract/2018-06-27/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/textract/2018-06-27/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker/2017-07-24/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker/2017-07-24/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker/2017-07-24/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker/2017-07-24/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sagemaker/2017-07-24/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/customer-profiles/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/customer-profiles/2020-08-15/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/customer-profiles/2020-08-15/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/customer-profiles/2020-08-15/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lex-models/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lex-models/2017-04-19/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lex-models/2017-04-19/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lex-models/2017-04-19/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lex-models/2017-04-19/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dataexchange/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dataexchange/2017-07-25/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dataexchange/2017-07-25/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dataexchange/2017-07-25/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/snowball/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/snowball/2016-06-30/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/snowball/2016-06-30/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/snowball/2016-06-30/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/snowball/2016-06-30/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm/2014-11-06/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm/2014-11-06/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm/2014-11-06/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm/2014-11-06/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ssm/2014-11-06/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/applicationcostprofiler/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/applicationcostprofiler/2020-09-10/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/applicationcostprofiler/2020-09-10/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/applicationcostprofiler/2020-09-10/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis/2013-12-02/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis/2013-12-02/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis/2013-12-02/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis/2013-12-02/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis/2013-12-02/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/devops-guru/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/devops-guru/2020-12-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/devops-guru/2020-12-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/devops-guru/2020-12-01/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ivs/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ivs/2020-07-14/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ivs/2020-07-14/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ivs/2020-07-14/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/stepfunctions/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/stepfunctions/2016-11-23/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/stepfunctions/2016-11-23/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/stepfunctions/2016-11-23/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/stepfunctions/2016-11-23/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/qldb/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/qldb/2019-01-02/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/qldb/2019-01-02/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/qldb/2019-01-02/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sesv2/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sesv2/2019-09-27/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sesv2/2019-09-27/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/sesv2/2019-09-27/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/servicecatalog/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/servicecatalog/2015-12-10/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/servicecatalog/2015-12-10/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/servicecatalog/2015-12-10/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/servicecatalog/2015-12-10/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediapackage-vod/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediapackage-vod/2018-11-07/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediapackage-vod/2018-11-07/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/mediapackage-vod/2018-11-07/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-09-29/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-09-29/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-09-29/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-09-29/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-11-25/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-11-25/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-11-25/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-11-25/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-11-25/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-04-17/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-04-17/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-04-17/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-04-17/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-05-31/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-05-31/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-05-31/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-05-31/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-07-27/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-07-27/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-07-27/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-07-27/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-10-21/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-10-21/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-10-21/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-10-21/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2018-11-05/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2018-11-05/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2018-11-05/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2018-11-05/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2018-11-05/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2017-03-25/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2017-03-25/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2017-03-25/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2017-03-25/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2017-03-25/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-08-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-08-01/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-08-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-08-01/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2017-10-30/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2017-10-30/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2017-10-30/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2017-10-30/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2017-10-30/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-01-28/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-01-28/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-01-28/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-01-28/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-09-17/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-09-17/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-09-17/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2015-09-17/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2020-05-31/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2020-05-31/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2020-05-31/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2020-05-31/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2020-05-31/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2018-06-18/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2018-06-18/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2018-06-18/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2018-06-18/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2018-06-18/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-09-07/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-09-07/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-09-07/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-09-07/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2019-03-26/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2019-03-26/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2019-03-26/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2019-03-26/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2019-03-26/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-08-20/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-08-20/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-08-20/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-08-20/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-01-13/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-01-13/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-01-13/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2016-01-13/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-11-06/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-11-06/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-11-06/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudfront/2014-11-06/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dynamodb/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dynamodb/2012-08-10/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dynamodb/2012-08-10/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dynamodb/2012-08-10/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dynamodb/2012-08-10/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dynamodb/2012-08-10/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lookoutequipment/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lookoutequipment/2020-12-15/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lookoutequipment/2020-12-15/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lookoutequipment/2020-12-15/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/waf/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/waf/2015-08-24/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/waf/2015-08-24/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/waf/2015-08-24/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/waf/2015-08-24/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot-data/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot-data/2015-05-28/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot-data/2015-05-28/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/iot-data/2015-05-28/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apprunner/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apprunner/2020-05-15/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apprunner/2020-05-15/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/apprunner/2020-05-15/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dms/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dms/2016-01-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dms/2016-01-01/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dms/2016-01-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dms/2016-01-01/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dms/2016-01-01/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resource-groups/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resource-groups/2017-11-27/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resource-groups/2017-11-27/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resource-groups/2017-11-27/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resource-groups/2017-11-27/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudtrail/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudtrail/2013-11-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudtrail/2013-11-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudtrail/2013-11-01/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloudtrail/2013-11-01/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint/2016-12-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint/2016-12-01/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/pinpoint/2016-12-01/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/fms/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/fms/2018-01-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/fms/2018-01-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/fms/2018-01-01/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/fms/2018-01-01/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53domains/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53domains/2014-05-15/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53domains/2014-05-15/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53domains/2014-05-15/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53domains/2014-05-15/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opsworks/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opsworks/2013-02-18/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opsworks/2013-02-18/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opsworks/2013-02-18/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opsworks/2013-02-18/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opsworks/2013-02-18/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/medialive/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/medialive/2017-10-14/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/medialive/2017-10-14/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/medialive/2017-10-14/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/medialive/2017-10-14/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-identity/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-identity/2021-04-20/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-identity/2021-04-20/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-identity/2021-04-20/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/amp/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/amp/2020-08-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/amp/2020-08-01/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/amp/2020-08-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/amp/2020-08-01/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lookoutmetrics/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lookoutmetrics/2017-07-25/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lookoutmetrics/2017-07-25/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lookoutmetrics/2017-07-25/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/accessanalyzer/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/accessanalyzer/2019-11-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/accessanalyzer/2019-11-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/accessanalyzer/2019-11-01/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appintegrations/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appintegrations/2020-07-29/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appintegrations/2020-07-29/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appintegrations/2020-07-29/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/amplify/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/amplify/2017-07-25/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/amplify/2017-07-25/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/amplify/2017-07-25/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/directconnect/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/directconnect/2012-10-25/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/directconnect/2012-10-25/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/directconnect/2012-10-25/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/directconnect/2012-10-25/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ecr-public/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ecr-public/2020-10-30/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ecr-public/2020-10-30/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ecr-public/2020-10-30/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ecs/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ecs/2014-11-13/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ecs/2014-11-13/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ecs/2014-11-13/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ecs/2014-11-13/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/ecs/2014-11-13/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/inspector/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/inspector/2015-08-18/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/inspector/2015-08-18/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/inspector/2016-02-16/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/inspector/2016-02-16/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/inspector/2016-02-16/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/inspector/2016-02-16/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/migrationhubstrategy/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/migrationhubstrategy/2020-02-19/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/migrationhubstrategy/2020-02-19/paginators-1.sdk-extras.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/migrationhubstrategy/2020-02-19/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/migrationhubstrategy/2020-02-19/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeartifact/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeartifact/2018-09-22/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeartifact/2018-09-22/paginators-1.sdk-extras.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeartifact/2018-09-22/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codeartifact/2018-09-22/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codestar-connections/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codestar-connections/2019-12-01/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codestar-connections/2019-12-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/codestar-connections/2019-12-01/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opsworkscm/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opsworkscm/2016-11-01/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opsworkscm/2016-11-01/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opsworkscm/2016-11-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opsworkscm/2016-11-01/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opsworkscm/2016-11-01/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/greengrass/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/greengrass/2017-06-07/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/greengrass/2017-06-07/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/greengrass/2017-06-07/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-meetings/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-meetings/2021-07-15/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-meetings/2021-07-15/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/chime-sdk-meetings/2021-07-15/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-media/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-media/2017-09-30/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-media/2017-09-30/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-media/2017-09-30/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/kinesis-video-media/2017-09-30/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connectparticipant/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connectparticipant/2018-09-07/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connectparticipant/2018-09-07/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/connectparticipant/2018-09-07/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lookoutvision/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lookoutvision/2020-11-20/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lookoutvision/2020-11-20/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/lookoutvision/2020-11-20/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dax/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dax/2017-04-19/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dax/2017-04-19/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dax/2017-04-19/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/dax/2017-04-19/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/servicecatalog-appregistry/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/servicecatalog-appregistry/2020-06-24/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/servicecatalog-appregistry/2020-06-24/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/servicecatalog-appregistry/2020-06-24/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-cluster/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-cluster/2019-12-02/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-cluster/2019-12-02/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/route53-recovery-cluster/2019-12-02/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/endpoints.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloud9/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloud9/2017-09-23/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloud9/2017-09-23/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloud9/2017-09-23/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/cloud9/2017-09-23/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-catalog/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-catalog/2018-09-17/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-catalog/2018-09-17/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/marketplace-catalog/2018-09-17/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/emr/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/emr/2009-03-31/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/emr/2009-03-31/waiters-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/emr/2009-03-31/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/emr/2009-03-31/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/emr/2009-03-31/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resourcegroupstaggingapi/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resourcegroupstaggingapi/2017-01-26/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resourcegroupstaggingapi/2017-01-26/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resourcegroupstaggingapi/2017-01-26/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/resourcegroupstaggingapi/2017-01-26/examples-1.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appconfig/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appconfig/2019-10-09/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appconfig/2019-10-09/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/appconfig/2019-10-09/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opensearch/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opensearch/2021-01-01/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opensearch/2021-01-01/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/opensearch/2021-01-01/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/personalize/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/personalize/2018-05-22/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/personalize/2018-05-22/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/personalize/2018-05-22/service-2.json  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/config/\n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/config/2014-11-12/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/config/2014-11-12/paginators-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/config/2014-11-12/service-2.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/botocore/data/config/2014-11-12/examples-1.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/libk5crypto.so.3  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/prettytable-2.0.0.dist-info/\n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/prettytable-2.0.0.dist-info/INSTALLER  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/prettytable-2.0.0.dist-info/METADATA  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/prettytable-2.0.0.dist-info/direct_url.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/prettytable-2.0.0.dist-info/RECORD  \n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/prettytable-2.0.0.dist-info/top_level.txt  \n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/prettytable-2.0.0.dist-info/REQUESTED  \n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli/prettytable-2.0.0.dist-info/WHEEL  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/prettytable-2.0.0.dist-info/COPYING  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/multidict/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/multidict/_multidict.cpython-39-x86_64-linux-gnu.so  \n",
      "   creating: /dli/task/ngc_assets/ngccli/ngc-cli/wcwidth/\n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/wcwidth/version.json  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/libffi.so.6  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/libssl.so.10  \n",
      "  inflating: /dli/task/ngc_assets/ngccli/ngc-cli/libstdc++.so.6  \n",
      " extracting: /dli/task/ngc_assets/ngccli/ngc-cli.md5  \n"
     ]
    }
   ],
   "source": [
    "# 2.1\n",
    "# DO NOT CHANGE THIS CELL\n",
    "import os\n",
    "os.environ['NGC_DIR']='/dli/task/ngc_assets'\n",
    "\n",
    "%env CLI=ngccli_cat_linux.zip\n",
    "!mkdir -p $NGC_DIR/ngccli\n",
    "!wget \"https://ngc.nvidia.com/downloads/$CLI\" -P $NGC_DIR/ngccli\n",
    "!unzip -u \"$NGC_DIR/ngccli/$CLI\" \\\n",
    "       -d $NGC_DIR/ngccli/\n",
    "!rm $NGC_DIR/ngccli/*.zip \n",
    "os.environ[\"PATH\"]=\"{}/ngccli/ngc-cli:{}\".format(os.getenv(\"NGC_DIR\", \"\"), os.getenv(\"PATH\", \"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d7bf605e-fe17-48a8-b1b6-70f594a83b43",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\n",
      "    \"application\": \"Question Answering\",\n",
      "    \"createdDate\": \"2021-08-18T20:04:58.595Z\",\n",
      "    \"description\": \"Question Answering Bert Large uncased model for extractive question answering on any provided content.\",\n",
      "    \"displayName\": \"Question Answering SQUAD2.0 Bert - Large\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"QA\",\n",
      "                \"NLP\",\n",
      "                \"SQUAD2.0\",\n",
      "                \"TAO\",\n",
      "                \"BERT Large\",\n",
      "                \"Riva\",\n",
      "                \"Question Answering\",\n",
      "                \"TAO Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 438459496,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"questionanswering_squad_english_bertlarge\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-04-08T02:44:05.680Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-01-06T17:12:08.183Z\",\n",
      "    \"description\": \"English Citrinet ASR model trained on ASR set 3.0, no-weight-decay\",\n",
      "    \"displayName\": \"RIVA Citrinet ASR English\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"English\",\n",
      "                \"STT\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Citrinet\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v3.0\",\n",
      "    \"latestVersionSizeInBytes\": 566722587,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_en_us_citrinet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:50:27.316Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"builtBy\": \"NVIDIA\",\n",
      "    \"createdDate\": \"2022-10-06T21:19:33.161Z\",\n",
      "    \"description\": \"Korean (ko-KR) Citrinet-1024 ASR model trained on ASR set 1.0\",\n",
      "    \"displayName\": \"RIVA Citrinet-1024 ASR Korean\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"AMP\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 213063789,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_ko_kr_citrinet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"AMP\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:49:07.894Z\"\n",
      "},{\n",
      "    \"application\": \"Object Detection\",\n",
      "    \"createdDate\": \"2021-08-16T15:03:42.235Z\",\n",
      "    \"description\": \"4 class object detection network to detect cars in an image.\",\n",
      "    \"displayName\": \"TrafficCamNet\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"CV\",\n",
      "                \"TAO\",\n",
      "                \"Transfer Learning\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"AI\",\n",
      "                \"Smart Cities\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"TLT\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"pruned_v1.0.3\",\n",
      "    \"latestVersionSizeInBytes\": 5454031,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"trafficcamnet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-15T16:18:31.000Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"builtBy\": \"NVIDIA\",\n",
      "    \"createdDate\": \"2022-10-06T21:20:23.015Z\",\n",
      "    \"description\": \"Korean (ko-KR) Conformer ASR model trained on ASR set 1.0\",\n",
      "    \"displayName\": \"RIVA Conformer ASR Korean\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 418150314,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_ko_kr_conformer\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:04:39.278Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-09-12T20:02:49.888Z\",\n",
      "    \"description\": \"Riva Marblenet Voice Activity Detection\",\n",
      "    \"displayName\": \"Riva Marblenet Voice Activity Detection\",\n",
      "    \"framework\": \"NeMo\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"NeMo\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 189576,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"voiceactivitydetection_marblenet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:54:26.023Z\"\n",
      "},{\n",
      "    \"application\": \"Punctuation and Capitalization\",\n",
      "    \"createdDate\": \"2021-08-18T20:05:02.000Z\",\n",
      "    \"description\": \"For each word in the input text, the model: 1) predicts a punctuation mark that should follow the word (if any), the model supports commas, periods and question marks) and 2) predicts if the word should be capitalized or not.\",\n",
      "    \"displayName\": \"Punctuation and Capitalization Bert\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"Punctuation\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"NLP\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Capitalization\",\n",
      "                \"BERT\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 438472343,\n",
      "    \"logo\": \"https://raw.githubusercontent.com/kbojo/images/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"punctuationcapitalization_english_bert\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T20:49:14.098Z\"\n",
      "},{\n",
      "    \"application\": \"Punctuation and Capitalization\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-03-31T21:37:40.065Z\",\n",
      "    \"description\": \"For each word in the input text, the model: 1) predicts a punctuation mark that should follow the word (if any), the model supports commas, periods and question marks) and 2) predicts if the word should be capitalized or not.\",\n",
      "    \"displayName\": \"RIVA Punctuation and Capitalization for Spanish\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"spanish\",\n",
      "                \"transfer learning\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"tao\",\n",
      "                \"Inference\",\n",
      "                \"bert\",\n",
      "                \"finetuning\",\n",
      "                \"natural-language-processing\",\n",
      "                \"tao toolkit\",\n",
      "                \"capitalization\",\n",
      "                \"nlp\",\n",
      "                \"riva\",\n",
      "                \"conversational-ai\",\n",
      "                \"punctuation\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v2.0\",\n",
      "    \"latestVersionSizeInBytes\": 670196415,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"punctuationcapitalization_es_us_bert_base\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:47:20.612Z\"\n",
      "},{\n",
      "    \"application\": \"HeartRateNet Estimation\",\n",
      "    \"createdDate\": \"2021-08-20T20:50:01.480Z\",\n",
      "    \"description\": \"Estimate heart-rate non-invasively from RGB facial videos.\",\n",
      "    \"displayName\": \"HeartRateNet\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Heart Rate estimation\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"TAO\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Healthcare\",\n",
      "                \"Computer Vision\",\n",
      "                \"TLT\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v2.0\",\n",
      "    \"latestVersionSizeInBytes\": 588677,\n",
      "    \"logo\": \"https://raw.githubusercontent.com/kbojo/images/master/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"heartratenet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-15T16:51:05.596Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-04-05T23:21:38.219Z\",\n",
      "    \"description\": \"Base Spanish grammar\",\n",
      "    \"displayName\": \"Riva ASR Spanish Inverse Normalization Grammar\",\n",
      "    \"framework\": \"Riva\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Riva\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"n/a\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v2.0\",\n",
      "    \"latestVersionSizeInBytes\": 4133083,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"FAR\",\n",
      "    \"name\": \"inverse_normalization_es_us\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"n/a\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:22:58.916Z\"\n",
      "},{\n",
      "    \"application\": \"Speaker Diarization\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-12-01T22:42:08.577Z\",\n",
      "    \"description\": \"Neural VAD model used in Riva Speaker Diarization\",\n",
      "    \"displayName\": \"RIVA Diarizer Neural VAD\",\n",
      "    \"framework\": \"NeMo\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"Speaker Recognition\",\n",
      "                \"Speaker Diarization\",\n",
      "                \"VAD\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"NeMo\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 348955,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"diarizer_vad_multilingual_marblenet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-01T22:42:10.179Z\"\n",
      "},{\n",
      "    \"application\": \"Fiducial Landmarks\",\n",
      "    \"createdDate\": \"2021-08-19T02:21:06.371Z\",\n",
      "    \"description\": \"Detect fiducial keypoints from an image of a face.\",\n",
      "    \"displayName\": \"Facial Landmarks Estimation\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Retail\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"Facial landmark estimation\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Computer Vision\",\n",
      "                \"TLT\",\n",
      "                \"Robotics\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v3.0\",\n",
      "    \"latestVersionSizeInBytes\": 2351014,\n",
      "    \"logo\": \"https://raw.githubusercontent.com/kbojo/images/master/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"fpenet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-15T16:06:46.780Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-06-16T16:03:55.256Z\",\n",
      "    \"description\": \"Hindi Conformer ASR model trained on ASR set 2.0\",\n",
      "    \"displayName\": \"RIVA Conformer ASR Hindi - ASR set 2.0\",\n",
      "    \"framework\": \"NeMo\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"NeMo\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_2.0\",\n",
      "    \"latestVersionSizeInBytes\": 272188608,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_hi_in_conformer\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:29:42.092Z\"\n",
      "},{\n",
      "    \"application\": \"Speech To Text\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-04-05T23:25:16.549Z\",\n",
      "    \"description\": \"Base Mandarin 4-gram LM\",\n",
      "    \"displayName\": \"Riva ASR Mandarin LM\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"mandarin\",\n",
      "                \"asr\",\n",
      "                \"lm\",\n",
      "                \"tao toolkit\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"tao\",\n",
      "                \"riva\",\n",
      "                \"Conversational AI\",\n",
      "                \"language models\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"NA\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v2.1\",\n",
      "    \"latestVersionSizeInBytes\": 8461503449,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"arpa\",\n",
      "    \"name\": \"speechtotext_zh_cn_lm\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"NA\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:24:08.443Z\"\n",
      "},{\n",
      "    \"application\": \"Text to Speech\",\n",
      "    \"createdDate\": \"2021-08-25T15:09:44.822Z\",\n",
      "    \"description\": \"Mel-Spectrogram prediction conditioned on input text with LJSpeech voice.\",\n",
      "    \"displayName\": \"Speech Synthesis English FastPitch\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"Text to Speech\",\n",
      "                \"English\",\n",
      "                \"TTS\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"Fastpitch\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.1\",\n",
      "    \"latestVersionSizeInBytes\": 82356302,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"speechsynthesis_english_fastpitch\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T19:51:29.397Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-11-11T00:49:53.002Z\",\n",
      "    \"description\": \"For each word in the input text, the model: predicts a punctuation mark that should follow the word (if any).\",\n",
      "    \"displayName\": \"RIVA Punctuation\",\n",
      "    \"framework\": \"NeMo\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"RIVA\",\n",
      "                \"NVIDIA AI Enterprise\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"NeMo\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v2.1\",\n",
      "    \"latestVersionSizeInBytes\": 670187898,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"punctuationcapitalization_it_it_bert_base\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-15T21:02:30.800Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva\",\n",
      "    \"builtBy\": \"NVIDIA\",\n",
      "    \"createdDate\": \"2022-11-11T00:28:35.155Z\",\n",
      "    \"description\": \"Riva multisepaker with IPA for G2P\",\n",
      "    \"displayName\": \"RIVA EnglishUS Hifigan\",\n",
      "    \"framework\": \"NeMo\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"NeMo\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 55759160,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"speechsynthesis_en_us_hifigan_ipa\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T19:58:55.183Z\"\n",
      "},{\n",
      "    \"application\": \"Object Detection\",\n",
      "    \"createdDate\": \"2021-08-16T15:53:38.516Z\",\n",
      "    \"description\": \"Pretrained weights to facilitate transfer learning using TAO Toolkit.\",\n",
      "    \"displayName\": \"TAO Pretrained Object Detection\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DSSD\",\n",
      "                \"DeepStream\",\n",
      "                \"Smart City\",\n",
      "                \"TAO\",\n",
      "                \"Industrial\",\n",
      "                \"SSD\",\n",
      "                \"Inspection\",\n",
      "                \"Public Safety\",\n",
      "                \"EfficientNet\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"ResNet\",\n",
      "                \"YOLO\",\n",
      "                \"Retail\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"FasterRCNN\",\n",
      "                \"TLT\",\n",
      "                \"RetinaNet\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"cspdarknet_tiny\",\n",
      "    \"latestVersionSizeInBytes\": 29955696,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"pretrained_object_detection\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-13T20:55:51.792Z\"\n",
      "},{\n",
      "    \"application\": \"Semantic Segmentation\",\n",
      "    \"createdDate\": \"2021-08-16T16:34:42.315Z\",\n",
      "    \"description\": \"Pretrained weights to facilitate transfer learning using Transfer Learning Toolkit.\",\n",
      "    \"displayName\": \"TAO Pretrained Semantic Segmentation\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Smart City\",\n",
      "                \"TAO\",\n",
      "                \"Industrial\",\n",
      "                \"Inspection\",\n",
      "                \"Public Safety\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"Robotics\",\n",
      "                \"UNet\",\n",
      "                \"Retail\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"Semantic Segmentation\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"TLT\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"vgg19\",\n",
      "    \"latestVersionSizeInBytes\": 161183816,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"pretrained_semantic_segmentation\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:19:16.272Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-01-06T18:06:44.126Z\",\n",
      "    \"description\": \"English Quartznet ASR model trained on ASR set 1.2\",\n",
      "    \"displayName\": \"RIVA Quartznet ASR English\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"English\",\n",
      "                \"STT\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"Quartznet\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.2\",\n",
      "    \"latestVersionSizeInBytes\": 70904250,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_en_us_quartznet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T20:48:34.825Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-11-11T00:50:42.208Z\",\n",
      "    \"description\": \"For each word in the input text, the model: predicts a punctuation mark that should follow the word (if any).\",\n",
      "    \"displayName\": \"RIVA Punctuation\",\n",
      "    \"framework\": \"NeMo\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"RIVA\",\n",
      "                \"NVIDIA AI Enterprise\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"NeMo\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v2.1\",\n",
      "    \"latestVersionSizeInBytes\": 620146438,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"punctuationcapitalization_ja_jp_bert_base\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-15T21:02:05.046Z\"\n",
      "},{\n",
      "    \"application\": \"NLP\",\n",
      "    \"createdDate\": \"2022-05-12T22:50:14.594Z\",\n",
      "    \"description\": \"Intent and Slot classification of the queries for the misty bot with BERT model trained on weather, smalltalk and POI (places of interest) data.\",\n",
      "    \"displayName\": \"Joint Intent and Slot Classification Misty Bert\",\n",
      "    \"framework\": \"TransferLearningToolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NLP\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"Intent and Slot Classification\",\n",
      "                \"Natural Language Processing\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"BERT\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"TransferLearningToolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 438931389,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"intentslotclassification_misty_english_bert\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-05-12T22:52:30.321Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"builtBy\": \"NVIDIA\",\n",
      "    \"createdDate\": \"2022-11-11T00:47:11.139Z\",\n",
      "    \"description\": \"Spanish EMEA (es-ES) Citrinet-1024 ASR model trained on ASR set 1.0\",\n",
      "    \"displayName\": \"RIVA Citrinet-1024 ASR Spanish EMEA\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"RIVA\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"AMP\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 566728046,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_es_es_citrinet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"AMP\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-15T20:58:02.708Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-09-22T23:18:04.410Z\",\n",
      "    \"description\": \"HifiGAN is a neural vocoder model for text-to-speech applications. It is intended as the second part of a two-stage speech synthesis pipeline, with a mel-spectrogram generator such as FastPitch as the first stage.\",\n",
      "    \"displayName\": \"RIVA EnglishUS Hifigan\",\n",
      "    \"framework\": \"NeMo\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"NeMo\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 55759177,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"speechsynthesis_en_us_hifigan\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T19:59:24.970Z\"\n",
      "},{\n",
      "    \"application\": \"Riva\",\n",
      "    \"createdDate\": \"2021-08-20T03:26:03.060Z\",\n",
      "    \"description\": \"Base English n-gram LM trained on LibriSpeech, Switchboard and Fisher\",\n",
      "    \"displayName\": \"Riva ASR English LM\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Finetuning\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 6244940310,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"speechtotext_english_lm\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:13:34.439Z\"\n",
      "},{\n",
      "    \"application\": \"CLASSIFICATION\",\n",
      "    \"createdDate\": \"2022-12-08T23:34:10.762Z\",\n",
      "    \"description\": \"Pretrained backbones for TAO Toolkit TF2 image classification\",\n",
      "    \"displayName\": \"TAO Pretrained Classification-TF2\",\n",
      "    \"framework\": \"TransferLearningToolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"TransferLearningToolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"efficientnet_b0\",\n",
      "    \"latestVersionSizeInBytes\": 47819977,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"SAVED_MODEL\",\n",
      "    \"name\": \"pretrained_classification_tf2\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-08T23:40:30.534Z\"\n",
      "},{\n",
      "    \"application\": \"OTHER\",\n",
      "    \"createdDate\": \"2021-08-19T02:21:06.246Z\",\n",
      "    \"description\": \"Detect body pose from an image.\",\n",
      "    \"displayName\": \"BodyPoseNet\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Retail\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"Body pose estimation\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Healthcare\",\n",
      "                \"TLT\",\n",
      "                \"Robotics\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0.1\",\n",
      "    \"latestVersionSizeInBytes\": 67193379,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"bodyposenet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-15T16:16:07.437Z\"\n",
      "},{\n",
      "    \"application\": \"Object Detection\",\n",
      "    \"createdDate\": \"2021-08-16T15:03:42.130Z\",\n",
      "    \"description\": \"4 class object detection network to detect cars in an image.\",\n",
      "    \"displayName\": \"DashCamNet\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"AI\",\n",
      "                \"TLT\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"pruned_v1.0.3\",\n",
      "    \"latestVersionSizeInBytes\": 6972038,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"dashcamnet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-15T16:07:37.884Z\"\n",
      "},{\n",
      "    \"application\": \"Speech To Text\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-04-08T04:37:39.406Z\",\n",
      "    \"description\": \"English Citrinet-256 ASR model trained on ASR set 2.0, no-weight-decay\",\n",
      "    \"displayName\": \"RIVA Citrinet 256 ASR English\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"asr\",\n",
      "                \"tao toolkit\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"tao\",\n",
      "                \"automatic_speech_recognition\",\n",
      "                \"conversational_ai\",\n",
      "                \"riva\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v2.0\",\n",
      "    \"latestVersionSizeInBytes\": 41140788,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"speechtotext_en_us_citrinet256\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:03:23.434Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva\",\n",
      "    \"builtBy\": \"NVIDIA\",\n",
      "    \"createdDate\": \"2022-07-15T07:42:58.910Z\",\n",
      "    \"description\": \"Base French 4-gram LM\",\n",
      "    \"displayName\": \"Riva ASR French LM\",\n",
      "    \"framework\": \"Riva\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"asr\",\n",
      "                \"lm\",\n",
      "                \"tao toolkit\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"tao\",\n",
      "                \"riva\",\n",
      "                \"Conversational AI\",\n",
      "                \"french\",\n",
      "                \"language models\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Riva\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"n/a\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v2.1\",\n",
      "    \"latestVersionSizeInBytes\": 713086783,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"ARPA\",\n",
      "    \"name\": \"speechtotext_fr_fr_lm\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"n/a\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:14:43.312Z\"\n",
      "},{\n",
      "    \"application\": \"Object Detection\",\n",
      "    \"createdDate\": \"2021-11-23T07:36:59.791Z\",\n",
      "    \"description\": \"Pretrained weights to facilitate transfer learning using TAO Toolkit.\",\n",
      "    \"displayName\": \"TAO Pretrained EfficientDet\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Smart City\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"TAO\",\n",
      "                \"Transfer Learning\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"AI\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"TLT\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"efficientnet_b2\",\n",
      "    \"latestVersionSizeInBytes\": 64864720,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"pretrained_efficientdet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-13T20:55:09.413Z\"\n",
      "},{\n",
      "    \"application\": \"Gaze Detection\",\n",
      "    \"createdDate\": \"2021-08-20T03:53:17.042Z\",\n",
      "    \"description\": \"Detect a persons eye gaze point of regard and gaze vector.\",\n",
      "    \"displayName\": \"Gaze Estimation\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Retail\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Computer Vision\",\n",
      "                \"TLT\",\n",
      "                \"Eye gaze estimation\",\n",
      "                \"Robotics\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 18282352,\n",
      "    \"logo\": \"https://raw.githubusercontent.com/kbojo/images/master/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"gazenet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-15T16:07:05.657Z\"\n",
      "},{\n",
      "    \"application\": \"Speech To Text\",\n",
      "    \"createdDate\": \"2022-06-16T15:51:02.239Z\",\n",
      "    \"description\": \"Base Hindi 3-gram LM\",\n",
      "    \"displayName\": \"Riva ASR Hindi LM\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"asr\",\n",
      "                \"tao toolkit\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"tao\",\n",
      "                \"kenlm\",\n",
      "                \"riva\",\n",
      "                \"Conversational AI\",\n",
      "                \"language model\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"AMP\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v3.1\",\n",
      "    \"latestVersionSizeInBytes\": 3488009941,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"BINARY\",\n",
      "    \"name\": \"speechtotext_hi_in_lm\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"AMP\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:26:52.105Z\"\n",
      "},{\n",
      "    \"application\": \"Action Recognition\",\n",
      "    \"createdDate\": \"2021-10-22T18:24:05.069Z\",\n",
      "    \"description\": \"5 class action recognition network to recognize what people do in an image.\",\n",
      "    \"displayName\": \"Action Recognition Net\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Smart City\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"TAO\",\n",
      "                \"Transfer Learning\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"AI\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"TLT\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v2.0\",\n",
      "    \"latestVersionSizeInBytes\": 310814833,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"actionrecognitionnet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-13T20:55:24.077Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-06-15T03:16:57.901Z\",\n",
      "    \"description\": \"Rusian Conformer ASR model trained on ASR set 1.0\",\n",
      "    \"displayName\": \"RIVA Conformer ASR Russian - ASR set 1.0\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"asr\",\n",
      "                \"tao toolkit\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"tao\",\n",
      "                \"russian\",\n",
      "                \"conformer\",\n",
      "                \"riva\",\n",
      "                \"Conversational AI\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v2.0\",\n",
      "    \"latestVersionSizeInBytes\": 276748357,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_ru_ru_conformer\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:49:39.176Z\"\n",
      "},{\n",
      "    \"application\": \"OBJECT_DETECTION\",\n",
      "    \"createdDate\": \"2022-12-08T23:33:54.449Z\",\n",
      "    \"description\": \"Pretrained efficientnet backbones for TAO Toolkit's efficientdet-tf2\",\n",
      "    \"displayName\": \"TAO Pretrained EfficientDet-TF2\",\n",
      "    \"framework\": \"TransferLearningToolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"TransferLearningToolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"efficientnet_b0\",\n",
      "    \"latestVersionSizeInBytes\": 47819977,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"SAVED_MODEL\",\n",
      "    \"name\": \"pretrained_efficientdet_tf2\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-13T20:55:12.875Z\"\n",
      "},{\n",
      "    \"application\": \"Named Entity Recognition\",\n",
      "    \"createdDate\": \"2021-08-18T20:04:57.311Z\",\n",
      "    \"description\": \"The model identifies a category/entity the word in the input text belongs to.\",\n",
      "    \"displayName\": \"Named Entity Recognition Bert\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"Named Entity Recognition\",\n",
      "                \"NLP\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"BERT\",\n",
      "                \"NER\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 440857990,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"namedentityrecognition_english_bert\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-04-08T02:43:41.863Z\"\n",
      "},{\n",
      "    \"application\": \"Object Detection\",\n",
      "    \"createdDate\": \"2022-05-12T22:31:10.383Z\",\n",
      "    \"description\": \"Model to detect one or more objects from a LIDAR point cloud file and return 3D bounding boxes.\",\n",
      "    \"displayName\": \"PointPillarNet\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"AI\",\n",
      "                \"TLT\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 5572394,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"pointpillarnet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:15:22.113Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-04-05T23:21:53.250Z\",\n",
      "    \"description\": \"Base German grammar\",\n",
      "    \"displayName\": \"Riva ASR German Inverse Normalization Grammar\",\n",
      "    \"framework\": \"Riva\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Riva\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"n/a\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 4128539,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"FAR\",\n",
      "    \"name\": \"inverse_normalization_de_de\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"n/a\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:51:03.943Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva\",\n",
      "    \"builtBy\": \"NVIDIA\",\n",
      "    \"createdDate\": \"2022-11-11T00:25:26.362Z\",\n",
      "    \"description\": \"Riva multisepaker with IPA for G2P\",\n",
      "    \"displayName\": \"RIVA EnglishUS Fastpitch\",\n",
      "    \"framework\": \"NeMo\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"NeMo\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 90691286,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"speechsynthesis_en_us_fastpitch_ipa\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T19:49:57.891Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-07-21T20:09:28.480Z\",\n",
      "    \"description\": \"For each word in the input text, the model predicts a punctuation mark that should follow the word (if any), the model supports commas, poornvirams, exclaimation marks and question marks.\",\n",
      "    \"displayName\": \"RIVA Punctuation and Capitalization for Hindi\",\n",
      "    \"framework\": \"NeMo\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"NeMo\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 882514166,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"punctuationcapitalization_hi_in_bert_base\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:28:22.783Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-06-16T16:02:29.388Z\",\n",
      "    \"description\": \"Hindi Citrinet ASR model trained on ASR set 1.0\",\n",
      "    \"displayName\": \"RIVA Citrinet ASR Hindi (hi-IN) - ASR set 1.0\",\n",
      "    \"framework\": \"NeMo\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"NeMo\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"AMP\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 566726299,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_hi_in_citrinet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"AMP\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:52:39.002Z\"\n",
      "},{\n",
      "    \"application\": \"Text to Speech\",\n",
      "    \"createdDate\": \"2021-08-25T15:59:16.226Z\",\n",
      "    \"description\": \"Universal waveform generator from mel-spectrograms.\",\n",
      "    \"displayName\": \"Speech Synthesis Waveglow\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"Text to Speech\",\n",
      "                \"TTS\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Waveglow\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 342214978,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"speechsynthesis_waveglow\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-04-08T02:44:11.922Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"builtBy\": \"NVIDIA\",\n",
      "    \"createdDate\": \"2022-07-15T06:57:19.368Z\",\n",
      "    \"description\": \"French (fr-FR) Conformer ASR model trained on ASR set 2.0\",\n",
      "    \"displayName\": \"RIVA Conformer ASR French\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v2.1\",\n",
      "    \"latestVersionSizeInBytes\": 486733049,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_fr_fr_conformer\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:27:14.779Z\"\n",
      "},{\n",
      "    \"application\": \"Speaker Diarization\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-12-01T22:41:04.317Z\",\n",
      "    \"description\": \"Embedding Extractor model used in Riva Speaker Diarization\",\n",
      "    \"displayName\": \"RIVA Diarizer Embedding Extractor\",\n",
      "    \"framework\": \"NeMo\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"asr\",\n",
      "                \"speaker diarization\",\n",
      "                \"riva\",\n",
      "                \"titanet\",\n",
      "                \"speaker recognition\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"NeMo\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 37480408,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"diarizer_titanet_small\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-01T22:41:07.315Z\"\n",
      "},{\n",
      "    \"application\": \"Object Detection\",\n",
      "    \"createdDate\": \"2021-08-16T15:03:41.798Z\",\n",
      "    \"description\": \"1 class object detection network to detect faces in an image.\",\n",
      "    \"displayName\": \"FaceDetectIR\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Object Detection\",\n",
      "                \"Smart City\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Public Safety\",\n",
      "                \"IR\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"Image Classification\",\n",
      "                \"Retail\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Healthcare\",\n",
      "                \"DetectNet_v2\",\n",
      "                \"TLT\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"pruned_v1.0.1\",\n",
      "    \"latestVersionSizeInBytes\": 9532530,\n",
      "    \"logo\": \"https://raw.githubusercontent.com/kbojo/images/master/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"facedetectir\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-15T16:15:13.899Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-11-11T00:51:28.529Z\",\n",
      "    \"description\": \"For each word in the input text, the model: 1) predicts a punctuation mark that should follow the word (if any), the model supports commas, periods and question marks) and 2) predicts if the word should be capitalized or not.\",\n",
      "    \"displayName\": \"RIVA Punctuation and Capitalization for Korean\",\n",
      "    \"framework\": \"NeMo\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"RIVA\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"NeMo\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v1.1\",\n",
      "    \"latestVersionSizeInBytes\": 436025233,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"punctuationcapitalization_ko_kr_bert_base\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-15T21:04:06.108Z\"\n",
      "},{\n",
      "    \"application\": \"Object Detection\",\n",
      "    \"createdDate\": \"2021-08-19T02:21:06.369Z\",\n",
      "    \"description\": \"Detect faces from an image.\",\n",
      "    \"displayName\": \"FaceDetect\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Object Detection\",\n",
      "                \"Smart City\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Public Safety\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"Retail\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Healthcare\",\n",
      "                \"DetectNet_v2\",\n",
      "                \"Computer Vision\",\n",
      "                \"TLT\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"pruned_quantized_v2.0.1\",\n",
      "    \"latestVersionSizeInBytes\": 5775090,\n",
      "    \"logo\": \"https://raw.githubusercontent.com/kbojo/images/master/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"facenet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-15T16:15:40.080Z\"\n",
      "},{\n",
      "    \"application\": \"Object Detection\",\n",
      "    \"createdDate\": \"2022-12-08T15:52:56.110Z\",\n",
      "    \"description\": \"3 class object detection network to detect people in an image.\",\n",
      "    \"displayName\": \"PeopleNet Transformer\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 90730324,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"peoplenet_transformer\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-09T19:42:33.684Z\"\n",
      "},{\n",
      "    \"application\": \"Joint Intent and Slot classification\",\n",
      "    \"createdDate\": \"2021-08-18T20:04:58.439Z\",\n",
      "    \"description\": \"Intent and Slot classification of the qeuries for the weather chat bot (trained on weather chat bot data).\",\n",
      "    \"displayName\": \"Joint Intent and Slot Classification Bert\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NLP\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"Intent and Slot Classification\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"BERT\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 443298808,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"intentslotclassification_weather_english_bert\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-04-08T02:43:36.984Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva\",\n",
      "    \"builtBy\": \"NVIDIA\",\n",
      "    \"createdDate\": \"2022-07-15T09:06:14.477Z\",\n",
      "    \"description\": \"Base English 3-gram LM\",\n",
      "    \"displayName\": \"Riva ASR English(en-GB) LM\",\n",
      "    \"framework\": \"Riva\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"asr\",\n",
      "                \"lm\",\n",
      "                \"tao toolkit\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"tao\",\n",
      "                \"riva\",\n",
      "                \"english\",\n",
      "                \"Conversational AI\",\n",
      "                \"en-gb\",\n",
      "                \"language models\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Riva\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"n/a\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 582300065,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"ARPA\",\n",
      "    \"name\": \"speechtotext_en_gb_lm\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"n/a\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:14:12.240Z\"\n",
      "},{\n",
      "    \"application\": \"Punctuation and Capitalization\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-03-31T21:38:24.169Z\",\n",
      "    \"description\": \"For each word in the input text, the model: 1) predicts a punctuation mark that should follow the word (if any), the model supports commas, periods and question marks) and 2) predicts if the word should be capitalized or not.\",\n",
      "    \"displayName\": \"RIVA Punctuation\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"transfer learning\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"tao\",\n",
      "                \"Inference\",\n",
      "                \"bert\",\n",
      "                \"finetuning\",\n",
      "                \"natural-language-processing\",\n",
      "                \"tao toolkit\",\n",
      "                \"capitalization\",\n",
      "                \"nlp\",\n",
      "                \"riva\",\n",
      "                \"conversational-ai\",\n",
      "                \"punctuation\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v2.0\",\n",
      "    \"latestVersionSizeInBytes\": 438282546,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"punctuationcapitalization_en_us_bert_base\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:50:08.052Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-12-15T21:13:54.118Z\",\n",
      "    \"description\": \"For each word in the input text, the model predicts a punctuation mark that should follow the word (if any), the model supports commas, periods and question marks\",\n",
      "    \"displayName\": \"RIVA Punctuation for Arabic\",\n",
      "    \"framework\": \"NeMo\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"RIVA\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"NeMo\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 408497303,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"punctuationcapitalization_ar_ar_bert_base\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-15T21:14:47.674Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-09-20T22:06:08.851Z\",\n",
      "    \"description\": \"FastPitch is a mel-spectrogram generator, designed to be used as the first part of a neural text-to-speech system in conjunction with a neural vocoder\",\n",
      "    \"displayName\": \"RIVA EnglishUS Fastpitch\",\n",
      "    \"framework\": \"NeMo\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"NeMo\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 90755625,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"speechsynthesis_en_us_fastpitch\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T19:50:35.446Z\"\n",
      "},{\n",
      "    \"application\": \"Character Recognition\",\n",
      "    \"createdDate\": \"2021-08-16T15:03:42.268Z\",\n",
      "    \"description\": \"Model to recognize characters from the image crop of a License Plate.\",\n",
      "    \"displayName\": \"License Plate Recognition\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Smart City\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Traffic\",\n",
      "                \"Public Safety\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"License Plate recognition\",\n",
      "                \"Computer Vision\",\n",
      "                \"TLT\",\n",
      "                \"OCR\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 231797006,\n",
      "    \"logo\": \"https://raw.githubusercontent.com/kbojo/images/master/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"lprnet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-15T16:19:11.177Z\"\n",
      "},{\n",
      "    \"application\": \"Domain Classification\",\n",
      "    \"createdDate\": \"2021-08-18T20:04:57.163Z\",\n",
      "    \"description\": \"Domain classification of the query for weather chat bot.\",\n",
      "    \"displayName\": \"Domain Classification English Bert\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NLP\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"Domain Classification\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"BERT\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 440794733,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"domainclassification_english_bert\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-04-08T02:43:45.183Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"builtBy\": \"NVIDIA\",\n",
      "    \"createdDate\": \"2022-11-11T00:42:33.571Z\",\n",
      "    \"description\": \"Spanish EMEA (es-ES) Conformer ASR model trained on ASR set 1.0\",\n",
      "    \"displayName\": \"RIVA Conformer ASR Spanish EMEA\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"TAO\",\n",
      "                \"nvidia ai\",\n",
      "                \"riva\",\n",
      "                \"nvidia ai enterprise supported\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 486998436,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_es_es_conformer\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-15T20:46:40.006Z\"\n",
      "},{\n",
      "    \"application\": \"Recognition\",\n",
      "    \"createdDate\": \"2022-12-09T04:16:26.343Z\",\n",
      "    \"description\": \"Embedding generator model to recognize objects on a checkout counter.\",\n",
      "    \"displayName\": \"Retail Object Recognition\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Smart City\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"TAO\",\n",
      "                \"Transfer Learning\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"AI\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"TLT\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 186598296,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"retail_object_recognition\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-13T20:54:41.460Z\"\n",
      "},{\n",
      "    \"application\": \"Text to Speech\",\n",
      "    \"createdDate\": \"2021-08-25T15:09:44.822Z\",\n",
      "    \"description\": \"GAN-based waveform generator from mel-spectrograms.\",\n",
      "    \"displayName\": \"Speech Synthesis HiFi-GAN\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"tao toolkit\",\n",
      "                \"tts\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"hifigan\",\n",
      "                \"tao\",\n",
      "                \"riva\",\n",
      "                \"text to speech\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 51892640,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"speechsynthesis_hifigan\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T19:48:58.047Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-01-06T17:20:04.171Z\",\n",
      "    \"description\": \"Russian Citrinet ASR model trained on ASR set 1.0\",\n",
      "    \"displayName\": \"RIVA Citrinet ASR Russian\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"STT\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"Russian\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Citrinet\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 566725641,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_ru_ru_citrinet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:51:45.846Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-04-20T17:44:38.494Z\",\n",
      "    \"description\": \"Spanish Conformer ASR model trained on ASR set 2.0.\",\n",
      "    \"displayName\": \"RIVA Conformer ASR Spanish\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Spanish\",\n",
      "                \"Conformer\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v2.1\",\n",
      "    \"latestVersionSizeInBytes\": 486998134,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_es_us_conformer\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T20:49:54.343Z\"\n",
      "},{\n",
      "    \"application\": \"OTHER\",\n",
      "    \"createdDate\": \"2022-12-08T23:33:07.209Z\",\n",
      "    \"description\": \"Semantic segmentation of persons in an image.\",\n",
      "    \"displayName\": \"CitySemSegFormer\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"Smart City\",\n",
      "                \"other\",\n",
      "                \"TAO\",\n",
      "                \"Transfer Learning\",\n",
      "                \"FP32\",\n",
      "                \"recipe\",\n",
      "                \"industry\",\n",
      "                \"HDF5\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"FP16\",\n",
      "                \"Retail\",\n",
      "                \"transfer-learning-toolkit\",\n",
      "                \"TLT\",\n",
      "                \"DeepStream\",\n",
      "                \"deep-learning\",\n",
      "                \"smart-cities\",\n",
      "                \"AI\",\n",
      "                \"INT8\",\n",
      "                \"technology\",\n",
      "                \"image-segmentation\",\n",
      "                \"computer-vision\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"application\",\n",
      "                \"TAO Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 347161829,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"citysemsegformer\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-14T05:34:54.451Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"builtBy\": \"NVIDIA\",\n",
      "    \"createdDate\": \"2022-11-11T00:44:55.128Z\",\n",
      "    \"description\": \"Japanese (ja-JP) Conformer ASR model trained on ASR set 3.0\",\n",
      "    \"displayName\": \"RIVA Conformer ASR Japanese\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"TAO\",\n",
      "                \"nvidia ai\",\n",
      "                \"riva\",\n",
      "                \"nvidia ai enterprise supported\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v3.0\",\n",
      "    \"latestVersionSizeInBytes\": 474821833,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_ja_jp_conformer\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-15T20:53:33.295Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-04-05T23:22:07.127Z\",\n",
      "    \"description\": \"Base English grammar\",\n",
      "    \"displayName\": \"Riva TTS English Normalization Grammar\",\n",
      "    \"framework\": \"Riva\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Riva\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"n/a\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.1\",\n",
      "    \"latestVersionSizeInBytes\": 2390007,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"FAR\",\n",
      "    \"name\": \"normalization_en_us\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"n/a\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-05-20T15:16:58.353Z\"\n",
      "},{\n",
      "    \"application\": \"Pose Classification\",\n",
      "    \"createdDate\": \"2022-05-12T22:31:11.382Z\",\n",
      "    \"description\": \"Pose classification network to classify poses of people from their skeletons.\",\n",
      "    \"displayName\": \"Pose Classification\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Transfer Learning\",\n",
      "                \"AI\",\n",
      "                \"Smart Cities\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Computer Vision\",\n",
      "                \"TLT\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 12730328,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"poseclassificationnet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-15T16:14:26.350Z\"\n",
      "},{\n",
      "    \"application\": \"Retail Object Detection\",\n",
      "    \"createdDate\": \"2022-12-08T23:34:26.149Z\",\n",
      "    \"description\": \"EfficientDet based object detection network to detect retail objects on a checkout counter.\",\n",
      "    \"displayName\": \"Retail Object Detection\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Smart City\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"TAO\",\n",
      "                \"Transfer Learning\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"AI\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"TLT\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_100_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 136126783,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"retail_object_detection\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-13T20:55:44.874Z\"\n",
      "},{\n",
      "    \"application\": \"Instance Segmentation\",\n",
      "    \"createdDate\": \"2021-08-16T15:03:42.177Z\",\n",
      "    \"description\": \"1 class instance segmentation network to detect and segment instances of people in an image.\",\n",
      "    \"displayName\": \"PeopleSegNet\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"AI\",\n",
      "                \"TLT\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v2.0.2\",\n",
      "    \"latestVersionSizeInBytes\": 73969636,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"peoplesegnet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-15T16:08:55.265Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva EA\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-03-17T23:05:19.998Z\",\n",
      "    \"description\": \"Base Spanish 4-gram LM\",\n",
      "    \"displayName\": \"Riva ASR Spanish LM\",\n",
      "    \"framework\": \"Riva\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Spanish\",\n",
      "                \"Citrinet\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Riva\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"n/a\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v2.0\",\n",
      "    \"latestVersionSizeInBytes\": 1067128899,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"ARPA\",\n",
      "    \"name\": \"speechtotext_es_us_lm\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"n/a\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:21:22.611Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"builtBy\": \"NVIDIA\",\n",
      "    \"createdDate\": \"2022-11-11T00:45:51.824Z\",\n",
      "    \"description\": \"Italian (it-IT) Conformer ASR model trained on ASR set 1.0\",\n",
      "    \"displayName\": \"RIVA Conformer ASR Italian\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"RIVA\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 488592459,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_it_it_conformer\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-15T20:55:23.459Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva EA\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-03-17T23:02:17.225Z\",\n",
      "    \"description\": \"Base Russian 4-gram LM\",\n",
      "    \"displayName\": \"Riva ASR Russian LM\",\n",
      "    \"framework\": \"Riva\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"Russian\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Citrinet\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Riva\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"n/a\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v2.0\",\n",
      "    \"latestVersionSizeInBytes\": 1218584607,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"ARPA\",\n",
      "    \"name\": \"speechtotext_ru_ru_lm\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"n/a\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:24:56.038Z\"\n",
      "},{\n",
      "    \"application\": \"Instance Segmentation\",\n",
      "    \"createdDate\": \"2021-08-16T16:34:42.327Z\",\n",
      "    \"description\": \"Pretrained weights to facilitate transfer learning using TAO Toolkit.\",\n",
      "    \"displayName\": \"TAO Pretrained Instance Segmentation\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Smart City\",\n",
      "                \"MaskRCNN\",\n",
      "                \"TAO\",\n",
      "                \"Inspection\",\n",
      "                \"Public Safety\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"Robotics\",\n",
      "                \"Retail\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"Instance Segmentation\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"TLT\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"resnet10\",\n",
      "    \"latestVersionSizeInBytes\": 40175904,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"pretrained_instance_segmentation\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:10:16.119Z\"\n",
      "},{\n",
      "    \"application\": \"Pose Estimation\",\n",
      "    \"createdDate\": \"2021-12-06T00:47:27.212Z\",\n",
      "    \"description\": \"3D human pose estimation network to predict 34 keypoints in 3D of a person in an image.\",\n",
      "    \"displayName\": \"BodyPose3DNet\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Smart City\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"Transfer Learning\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Smart Cities\",\n",
      "                \"AI\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"Computer Vision\",\n",
      "                \"Transfer Learning Toolkit\",\n",
      "                \"Deep Learning\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_performance_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 40360415,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"bodypose3dnet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2021-12-09T20:57:24.893Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"createdDate\": \"2021-08-18T20:04:57.753Z\",\n",
      "    \"description\": \"Speech to Text Citrinet models for English.\",\n",
      "    \"displayName\": \"Speech to Text English Citrinet\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"English\",\n",
      "                \"STT\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Citrinet\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v3.0\",\n",
      "    \"latestVersionSizeInBytes\": 566724116,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"speechtotext_english_citrinet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:12:00.392Z\"\n",
      "},{\n",
      "    \"application\": \"Question Answering\",\n",
      "    \"createdDate\": \"2021-08-18T20:04:58.627Z\",\n",
      "    \"description\": \"Question Answering Bert Base uncased model for extractive question answering on any provided content.\",\n",
      "    \"displayName\": \"Question Answering SQUAD2.0 Bert\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"QA\",\n",
      "                \"NLP\",\n",
      "                \"SQUAD2.0\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"Question Answering\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"BERT\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 438459496,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"questionanswering_squad_english_bert\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-04-08T02:44:00.138Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva\",\n",
      "    \"builtBy\": \"NVIDIA\",\n",
      "    \"createdDate\": \"2022-10-06T21:15:50.885Z\",\n",
      "    \"description\": \"Base Brazilian Portuguese 4-gram LM\",\n",
      "    \"displayName\": \"Riva ASR Brazilian Portuguese LM\",\n",
      "    \"framework\": \"Riva\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Riva\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"n/a\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 1227687850,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"ARPA\",\n",
      "    \"name\": \"speechtotext_pt_br_lm\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"n/a\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:30:25.960Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"createdDate\": \"2022-03-23T11:50:58.191Z\",\n",
      "    \"description\": \"German Conformer ASR model trained on ASR set 2.0\",\n",
      "    \"displayName\": \"RIVA Conformer ASR German\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"German\",\n",
      "                \"Conformer\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v2.0\",\n",
      "    \"latestVersionSizeInBytes\": 488591508,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"speechtotext_de_de_conformer\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:03:45.774Z\"\n",
      "},{\n",
      "    \"application\": \"Classification\",\n",
      "    \"createdDate\": \"2021-08-16T15:03:42.190Z\",\n",
      "    \"description\": \"Resnet18 model to classify a car crop into 1 out 6 car types.\",\n",
      "    \"displayName\": \"VehicleTypeNet\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Object Detection\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"Smart City\",\n",
      "                \"TAO\",\n",
      "                \"Traffic\",\n",
      "                \"Public Safety\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"Image Classification\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"TLT\",\n",
      "                \"NVIDIA AI\",\n",
      "                \"Vehicle Classification\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"pruned_v1.0.1\",\n",
      "    \"latestVersionSizeInBytes\": 19980344,\n",
      "    \"logo\": \"https://raw.githubusercontent.com/kbojo/images/master/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"vehicletypenet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-15T16:45:41.354Z\"\n",
      "},{\n",
      "    \"application\": \"Joint Intent And Slot Classification\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-04-08T04:38:25.037Z\",\n",
      "    \"description\": \"Intent and Slot classification of the queries for the misty bot with DistilBert model trained on weather, smalltalk and POI (places of interest) data.\",\n",
      "    \"displayName\": \"Joint Intent and Slot Classification DistilBert\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NLP\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"Natural Language Processing\",\n",
      "                \"Intent and slot classification\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"BERT\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 266351975,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"intentslotclassification_misty_english_distilbert\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-04-08T04:50:25.861Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-11-11T00:52:05.519Z\",\n",
      "    \"description\": \"For each word in the input text, the model: 1) predicts a punctuation mark that should follow the word (if any), the model supports commas, periods and question marks) and 2) predicts if the word should be capitalized or not.\",\n",
      "    \"displayName\": \"RIVA Punctuation and Capitalization for Brazilian Portuguese\",\n",
      "    \"framework\": \"NeMo\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"RIVA\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"NeMo\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 670191824,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"punctuationcapitalization_pt_br_bert_base\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-15T21:05:44.476Z\"\n",
      "},{\n",
      "    \"application\": \"Emotion Classification\",\n",
      "    \"createdDate\": \"2021-08-19T02:21:06.369Z\",\n",
      "    \"description\": \"Network to classify emotions from face.\",\n",
      "    \"displayName\": \"EmotionNet\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Retail\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Healthcare\",\n",
      "                \"Computer Vision\",\n",
      "                \"TLT\",\n",
      "                \"Emotion Recognition\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 4588024,\n",
      "    \"logo\": \"https://raw.githubusercontent.com/kbojo/images/master/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"emotionnet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-15T16:46:03.532Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-01-06T17:17:07.715Z\",\n",
      "    \"description\": \"German Citrinet ASR model trained on ASR set 2.0\",\n",
      "    \"displayName\": \"RIVA Citrinet ASR German\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"STT\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"German\",\n",
      "                \"Citrinet\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v2.0\",\n",
      "    \"latestVersionSizeInBytes\": 566726189,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_de_de_citrinet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:12:30.123Z\"\n",
      "},{\n",
      "    \"application\": \"Punctuation and Capitalization\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-03-31T21:36:59.700Z\",\n",
      "    \"description\": \"For each word in the input text, the model: 1) predicts a punctuation mark that should follow the word (if any), the model supports commas, periods and question marks) and 2) predicts if the word should be capitalized or not.\",\n",
      "    \"displayName\": \"RIVA Punctuation and Capitalization for German\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"german\",\n",
      "                \"transfer learning\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"tao\",\n",
      "                \"Inference\",\n",
      "                \"bert\",\n",
      "                \"finetuning\",\n",
      "                \"natural-language-processing\",\n",
      "                \"tao toolkit\",\n",
      "                \"capitalization\",\n",
      "                \"nlp\",\n",
      "                \"riva\",\n",
      "                \"conversational-ai\",\n",
      "                \"punctuation\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 712286911,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"punctuationcapitalization_de_de_bert_base\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:20:12.114Z\"\n",
      "},{\n",
      "    \"application\": \"Object Detection\",\n",
      "    \"createdDate\": \"2021-08-16T15:03:42.144Z\",\n",
      "    \"description\": \"Object Detection network to detect license plates in an image of a car.\",\n",
      "    \"displayName\": \"LPDNet\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Object Detection\",\n",
      "                \"Smart City\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Traffic\",\n",
      "                \"Public Safety\",\n",
      "                \"License plate detection\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"DetectNet_v2\",\n",
      "                \"Computer Vision\",\n",
      "                \"TLT\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"pruned_v2.1\",\n",
      "    \"latestVersionSizeInBytes\": 3975758,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"lpdnet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-15T16:11:34.699Z\"\n",
      "},{\n",
      "    \"application\": \"Classification\",\n",
      "    \"createdDate\": \"2021-08-16T15:53:38.509Z\",\n",
      "    \"description\": \"Pretrained weights to facilitate transfer learning using TAO Toolkit.\",\n",
      "    \"displayName\": \"TAO Pretrained Classification\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Smart City\",\n",
      "                \"TAO\",\n",
      "                \"Industrial\",\n",
      "                \"Inspection\",\n",
      "                \"Public Safety\",\n",
      "                \"EfficientNet\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"ResNet\",\n",
      "                \"Retail\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"VGG\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"TLT\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"cspdarknet_tiny\",\n",
      "    \"latestVersionSizeInBytes\": 29955696,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"pretrained_classification\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-13T20:54:06.799Z\"\n",
      "},{\n",
      "    \"application\": \"Object Detection\",\n",
      "    \"createdDate\": \"2021-08-16T15:53:38.600Z\",\n",
      "    \"description\": \"Pretrained weights to facilitate transfer learning using TAO Toolkit.\",\n",
      "    \"displayName\": \"TAO Pretrained DetectNet V2\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Retail\",\n",
      "                \"Smart City\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"TAO\",\n",
      "                \"Industrial\",\n",
      "                \"Inspection\",\n",
      "                \"Public Safety\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"DetectNet_v2\",\n",
      "                \"Smart Infrastructure\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"resnet34\",\n",
      "    \"latestVersionSizeInBytes\": 178944632,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"pretrained_detectnet_v2\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-13T20:54:58.656Z\"\n",
      "},{\n",
      "    \"application\": \"Text to Speech\",\n",
      "    \"createdDate\": \"2021-08-25T15:09:45.349Z\",\n",
      "    \"description\": \"Mel-Spectrogram prediction conditioned on input text with LJSpeech voice.\",\n",
      "    \"displayName\": \"Speech Synthesis English Tacotron2\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"Text to Speech\",\n",
      "                \"English\",\n",
      "                \"TTS\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Tacotron2\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 112824320,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"speechsynthesis_english_tacotron2\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-04-08T02:45:53.780Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"createdDate\": \"2021-08-18T20:04:57.047Z\",\n",
      "    \"description\": \"Speech to Text Jasper model for English.\",\n",
      "    \"displayName\": \"Speech to Text English Jasper\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"English\",\n",
      "                \"Jasper\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.2\",\n",
      "    \"latestVersionSizeInBytes\": 1234711099,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"speechtotext_english_jasper\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T20:48:55.883Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-03-29T23:17:55.307Z\",\n",
      "    \"description\": \"Mandarin Citrinet ASR model trained on ASR set 2.0\",\n",
      "    \"displayName\": \"RIVA Citrinet ASR Mandarin\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Mandarin\",\n",
      "                \"Citrinet\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v2.1\",\n",
      "    \"latestVersionSizeInBytes\": 583781459,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_zh_cn_citrinet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:15:46.724Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva\",\n",
      "    \"builtBy\": \"NVIDIA\",\n",
      "    \"createdDate\": \"2022-10-06T21:21:46.866Z\",\n",
      "    \"description\": \"Base Korean 4-gram LM\",\n",
      "    \"displayName\": \"Riva ASR Korean LM\",\n",
      "    \"framework\": \"Riva\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Riva\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"n/a\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 743249224,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"ARPA\",\n",
      "    \"name\": \"speechtotext_ko_kr_lm\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"n/a\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:26:04.085Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"createdDate\": \"2021-08-18T20:04:59.381Z\",\n",
      "    \"description\": \"Speech to Text Quartznet model for English.\",\n",
      "    \"displayName\": \"Speech to Text English QuartzNet\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"English\",\n",
      "                \"STT\",\n",
      "                \"Quartznet\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.2\",\n",
      "    \"latestVersionSizeInBytes\": 70904250,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"speechtotext_english_quartznet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-03-26T03:24:08.235Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"builtBy\": \"NVIDIA\",\n",
      "    \"createdDate\": \"2022-10-06T21:14:57.156Z\",\n",
      "    \"description\": \"Brazilian Portuguese (pt-BR) Conformer ASR model trained on ASR set 1.0\",\n",
      "    \"displayName\": \"RIVA Conformer ASR Brazilian Portuguese\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 276039081,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_pt_br_conformer\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:55:58.628Z\"\n",
      "},{\n",
      "    \"application\": \"Classification\",\n",
      "    \"createdDate\": \"2021-08-16T15:03:41.810Z\",\n",
      "    \"description\": \"Resnet18 model to classify a car crop into 1 out 20 car brands.\",\n",
      "    \"displayName\": \"VehicleMakeNet\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Smart City\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Traffic\",\n",
      "                \"Public Safety\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"Image Classification\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Computer Vision\",\n",
      "                \"TLT\",\n",
      "                \"Vehicle Classification\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"pruned_v1.0.1\",\n",
      "    \"latestVersionSizeInBytes\": 17247772,\n",
      "    \"logo\": \"https://raw.githubusercontent.com/kbojo/images/master/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"vehiclemakenet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-15T16:11:06.187Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-07-21T21:47:01.676Z\",\n",
      "    \"description\": \"For each word in the input text, the model: 1) predicts a punctuation mark that should follow the word (if any), the model supports commas, periods, hyphens and question marks) and 2) predicts if the word should be capitalized or not.\",\n",
      "    \"displayName\": \"RIVA Punctuation and Capitalization for French\",\n",
      "    \"framework\": \"NeMo\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"NeMo\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v2.0\",\n",
      "    \"latestVersionSizeInBytes\": 670195137,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"RIVA\",\n",
      "    \"name\": \"punctuationcapitalization_fr_fr_bert_base\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:45:21.272Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"builtBy\": \"NVIDIA\",\n",
      "    \"createdDate\": \"2022-10-06T21:09:05.061Z\",\n",
      "    \"description\": \"Brazilian Portuguese (pt-BR) Citrinet-1024 ASR model trained on ASR set 1.0\",\n",
      "    \"displayName\": \"RIVA Citrinet-1024 ASR Brazilian Portuguese\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"AMP\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 268199570,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_pt_br_citrinet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"AMP\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:17:35.823Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva EA\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-03-17T23:00:07.376Z\",\n",
      "    \"description\": \"Base German 4-gram LM\",\n",
      "    \"displayName\": \"Riva ASR German LM\",\n",
      "    \"framework\": \"Riva\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"German\",\n",
      "                \"Citrinet\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Riva\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"n/a\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v2.1\",\n",
      "    \"latestVersionSizeInBytes\": 2006212953,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"ARPA\",\n",
      "    \"name\": \"speechtotext_de_de_lm\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"n/a\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-09-10T03:16:03.853Z\"\n",
      "},{\n",
      "    \"application\": \"Object Detection\",\n",
      "    \"createdDate\": \"2021-08-16T15:03:41.786Z\",\n",
      "    \"description\": \"3 class object detection network to detect people in an image.\",\n",
      "    \"displayName\": \"PeopleNet\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Object Detection\",\n",
      "                \"Smart City\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"People Detection\",\n",
      "                \"TAO\",\n",
      "                \"Public Safety\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"Robotics\",\n",
      "                \"Retail\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Healthcare\",\n",
      "                \"DetectNet_v2\",\n",
      "                \"Computer Vision\",\n",
      "                \"TLT\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"pruned_quantized_v2.3.2\",\n",
      "    \"latestVersionSizeInBytes\": 8957525,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"peoplenet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-15T16:16:32.018Z\"\n",
      "},{\n",
      "    \"application\": \"ReIdentification\",\n",
      "    \"createdDate\": \"2022-12-08T23:32:19.492Z\",\n",
      "    \"description\": \"Re-Identification network to generate embeddings for identifying persons in different scenes.\",\n",
      "    \"displayName\": \"Re-Identification\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"Smart City\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"TAO\",\n",
      "                \"Transfer Learning\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"AI\",\n",
      "                \"Smart Infrastructure\",\n",
      "                \"TLT\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 96377716,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"reidentificationnet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-13T20:55:58.697Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-01-06T18:12:16.343Z\",\n",
      "    \"description\": \"Base English n-gram LM trained on LibriSpeech, Switchboard and Fisher\",\n",
      "    \"displayName\": \"Riva ASR English(en-US) LM\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"LM\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"Vertex AI Workbench\",\n",
      "                \"Google Cloud\",\n",
      "                \"English\",\n",
      "                \"One Click Deploy\",\n",
      "                \"Vertex AI\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Quick Deploy\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"n/a\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v4.1\",\n",
      "    \"latestVersionSizeInBytes\": 8605186199,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"ARPA\",\n",
      "    \"name\": \"speechtotext_en_us_lm\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"n/a\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:04:08.484Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"builtBy\": \"NVIDIA\",\n",
      "    \"createdDate\": \"2022-07-15T12:35:14.960Z\",\n",
      "    \"description\": \"English (en-GB) Conformer ASR model trained on ASR set 1.0\",\n",
      "    \"displayName\": \"RIVA Conformer ASR English\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"Tao Toolkit\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 488593412,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_en_gb_conformer\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:13:09.046Z\"\n",
      "},{\n",
      "    \"application\": \"OTHER\",\n",
      "    \"createdDate\": \"2021-08-24T21:13:00.968Z\",\n",
      "    \"description\": \"Semantic segmentation of persons in an image.\",\n",
      "    \"displayName\": \"PeopleSemSegnet\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"other\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"deep-learning\",\n",
      "                \"smart-cities\",\n",
      "                \"recipe\",\n",
      "                \"AI\",\n",
      "                \"FP32\",\n",
      "                \"HDF5\",\n",
      "                \"industry\",\n",
      "                \"INT8\",\n",
      "                \"technology\",\n",
      "                \"image-segmentation\",\n",
      "                \"FP16\",\n",
      "                \"Deep Learning\",\n",
      "                \"Retail\",\n",
      "                \"computer-vision\",\n",
      "                \"application\",\n",
      "                \"transfer-learning-toolkit\",\n",
      "                \"TLT\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_quantized_vanilla_unet_v2.0\",\n",
      "    \"latestVersionSizeInBytes\": 124471635,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"peoplesemsegnet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-15T16:10:16.167Z\"\n",
      "},{\n",
      "    \"application\": \"Question Answering\",\n",
      "    \"createdDate\": \"2021-08-18T20:05:00.928Z\",\n",
      "    \"description\": \"Question Answering Megatron uncased model for extractive question answering on any provided content.\",\n",
      "    \"displayName\": \"Question Answering SQUAD2.0 Megatron\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"QA\",\n",
      "                \"NLP\",\n",
      "                \"SQUAD2.0\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"Question Answering\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Megatron\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 1337603607,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"questionanswering_squad_english_megatron\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-04-08T02:43:28.489Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-01-06T18:04:05.681Z\",\n",
      "    \"description\": \"English Conformer ASR model for en-US\",\n",
      "    \"displayName\": \"RIVA Conformer ASR English(en-US)\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"English\",\n",
      "                \"STT\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Conformer\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v4.0\",\n",
      "    \"latestVersionSizeInBytes\": 486998256,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_en_us_conformer\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:41:58.678Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"builtBy\": \"NVIDIA\",\n",
      "    \"createdDate\": \"2022-11-11T00:46:33.666Z\",\n",
      "    \"description\": \"Arabic (ar-AR) Conformer ASR model trained on ASR set 1.0\",\n",
      "    \"displayName\": \"RIVA Conformer ASR Arabic\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"RIVA\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 486733079,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_ar_ar_conformer\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-15T20:56:24.590Z\"\n",
      "},{\n",
      "    \"application\": \"Gesture Classification\",\n",
      "    \"createdDate\": \"2021-08-19T02:21:06.246Z\",\n",
      "    \"description\": \"Classify gestures from hand crop images.\",\n",
      "    \"displayName\": \"GestureNet\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"DeepStream\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Gesture recognition\",\n",
      "                \"Robotics\",\n",
      "                \"Retail\",\n",
      "                \"CV\",\n",
      "                \"Metropolis\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Healthcare\",\n",
      "                \"Computer Vision\",\n",
      "                \"TLT\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"FP32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v2.0.2\",\n",
      "    \"latestVersionSizeInBytes\": 46124320,\n",
      "    \"logo\": \"https://raw.githubusercontent.com/kbojo/images/master/Nvidia-Centric-TAO.png\",\n",
      "    \"modelFormat\": \"TLT\",\n",
      "    \"name\": \"gesturenet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"FP32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-15T16:19:32.832Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva EA\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-03-09T01:27:18.447Z\",\n",
      "    \"description\": \"Contains files used in rmir creation\",\n",
      "    \"displayName\": \"Riva TTS English US Auxiliary Files\",\n",
      "    \"framework\": \"Riva\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"Riva\",\n",
      "                \"Conversational AI\",\n",
      "                \"Speech Synthesis\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Riva\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"n/a\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.3\",\n",
      "    \"latestVersionSizeInBytes\": 6815138,\n",
      "    \"logo\": \"https://dz112fgwz7ogh.cloudfront.net/logos/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"n/a\",\n",
      "    \"name\": \"speechsynthesis_en_us_auxiliary_files\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"n/a\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T19:49:32.852Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"builtBy\": \"NVIDIA\",\n",
      "    \"createdDate\": \"2022-07-15T07:11:42.166Z\",\n",
      "    \"description\": \"Mandarin (zh-CN) Conformer ASR model trained on ASR set 2.0\",\n",
      "    \"displayName\": \"RIVA Conformer ASR Mandarin\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp32\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v3.0\",\n",
      "    \"latestVersionSizeInBytes\": 478130474,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_zh_cn_conformer\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp32\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:40:35.651Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-04-05T23:21:15.510Z\",\n",
      "    \"description\": \"Base English grammar\",\n",
      "    \"displayName\": \"Riva ASR English Inverse Normalization Grammar\",\n",
      "    \"framework\": \"Riva\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Riva\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"n/a\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v2.0a\",\n",
      "    \"latestVersionSizeInBytes\": 2526035,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"FAR\",\n",
      "    \"name\": \"inverse_normalization_en_us\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"n/a\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:27:38.713Z\"\n",
      "},{\n",
      "    \"application\": \"NVIDIA Riva\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-10-17T06:59:57.578Z\",\n",
      "    \"description\": \"Base French grammar\",\n",
      "    \"displayName\": \"Riva ASR French Inverse Normalization Grammar\",\n",
      "    \"framework\": \"Riva\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Riva\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"n/a\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.0\",\n",
      "    \"latestVersionSizeInBytes\": 3003583,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"FAR\",\n",
      "    \"name\": \"inverse_normalization_fr_fr\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"n/a\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:46:23.405Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-01-06T17:15:39.660Z\",\n",
      "    \"description\": \"Spanish Citrinet ASR model trained on ASR set 2.0\",\n",
      "    \"displayName\": \"RIVA Citrinet ASR Spanish\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"STT\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"Spanish\",\n",
      "                \"Citrinet\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"AMP\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"trainable_v2.0\",\n",
      "    \"latestVersionSizeInBytes\": 566726427,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_es_us_citrinet\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"AMP\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T14:56:23.641Z\"\n",
      "},{\n",
      "    \"application\": \"Speech to Text\",\n",
      "    \"builtBy\": \"aiapps\",\n",
      "    \"createdDate\": \"2022-01-06T18:08:01.771Z\",\n",
      "    \"description\": \"English ASR model trained on ASR Set 1.2, Noise Robust\",\n",
      "    \"displayName\": \"RIVA Jasper ASR English\",\n",
      "    \"framework\": \"Transfer Learning Toolkit\",\n",
      "    \"isPublic\": true,\n",
      "    \"labels\": [\n",
      "        {\n",
      "            \"key\": \"builtBy\",\n",
      "            \"values\": [\n",
      "                \"aiapps\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"general\",\n",
      "            \"values\": [\n",
      "                \"ASR\",\n",
      "                \"English\",\n",
      "                \"Jasper\",\n",
      "                \"STT\",\n",
      "                \"NVIDIA AI Enterprise Supported\",\n",
      "                \"TAO\",\n",
      "                \"Riva\",\n",
      "                \"TAO Toolkit\",\n",
      "                \"NVIDIA AI\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"framework\",\n",
      "            \"values\": [\n",
      "                \"Transfer Learning Toolkit\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"precision\",\n",
      "            \"values\": [\n",
      "                \"fp16\"\n",
      "            ]\n",
      "        },\n",
      "        {\n",
      "            \"key\": \"publisher\",\n",
      "            \"values\": [\n",
      "                \"NVIDIA\"\n",
      "            ]\n",
      "        }\n",
      "    ],\n",
      "    \"latestVersionIdStr\": \"deployable_v1.2\",\n",
      "    \"latestVersionSizeInBytes\": 1234711099,\n",
      "    \"logo\": \"https://github.com/kbojo/images/raw/master/Nvidia-Centric-TAO-RIVA.png\",\n",
      "    \"modelFormat\": \"riva\",\n",
      "    \"name\": \"speechtotext_en_us_jasper\",\n",
      "    \"orgName\": \"nvidia\",\n",
      "    \"precision\": \"fp16\",\n",
      "    \"publisher\": \"NVIDIA\",\n",
      "    \"teamName\": \"tao\",\n",
      "    \"updatedDate\": \"2022-12-16T20:48:12.368Z\"\n",
      "}]\n"
     ]
    }
   ],
   "source": [
    "# 2.2\n",
    "# DO NOT CHANGE THIS CELL\n",
    "!ngc registry model list nvidia/tao/* --column name --column repository --column application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8e46b6d8-bc0a-4db6-b0b7-285b8d0a2b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"download_end\": \"2022-12-23 06:44:08.620572\",\n",
      "    \"download_start\": \"2022-12-23 06:44:04.614963\",\n",
      "    \"download_time\": \"4s\",\n",
      "    \"files_downloaded\": 3,\n",
      "    \"local_path\": \"/dli/task/ngc_assets/dashcamnet_vpruned_v1.0\",\n",
      "    \"size_downloaded\": \"6.65 MB\",\n",
      "    \"status\": \"Completed\",\n",
      "    \"transfer_id\": \"dashcamnet_vpruned_v1.0\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# 2.3\n",
    "!ngc registry model download-version nvidia/tao/dashcamnet:pruned_v1.0 --dest $NGC_DIR \\\n",
    "2>&1| tee my_assessment/answer_2.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67c7764a-2126-44a3-b4d7-b18885d923d4",
   "metadata": {},
   "source": [
    "### Step 3: Edit the Inference Configuration File ###\n",
    "The next step is to modify the Gst-nvinfer configuration file that will be used to configure the AI inference plugin. You can create a new text file for this purpose manually and start from scratch or use the [template provided](spec_files/pgie_config_dashcamnet.txt). You can also refer to sample applications and configuration files [here](https://github.com/NVIDIA-AI-IOT/deepstream_python_apps). When creating the configuration file, below are the fields to pay attention to: \n",
    "\n",
    "Following properties are used when using TAO Toolkit models downloaded from NGC: \n",
    "* `tlt-encoded-model` - Pathname of the TAO Toolkit encoded model\n",
    "* `tlt-model-key` - Model load key for the TAO Toolkit encoded model\n",
    "* `labelfile-path` - Pathname of a text file containing the labels for the model\n",
    "* `int8-calib-file` - Pathname of the INT8 calibration file for dynamic range adjustment with an FP32 model (only in INT8)\n",
    "* `uff-input-blob-name` - Name of the input blob in the UFF file\n",
    "* `output-blob-names` - Array of output layer names\n",
    "* `input-dims` - Dimensions of the model as [channel; height; width; input-order] if input-order=0 i.e. NCHW\n",
    "* `net-scale-factor` - Pixel normalization factor _(default=1)_\n",
    "\n",
    "Recommended properties: \n",
    "* `batch-size` - Number of frames to be inferred together in a batch _(default=1)_\n",
    "\n",
    "Mandatory properties for detectors: \n",
    "* `num-detected-classes` - Number of classes detected by the network\n",
    "\n",
    "Optional properties for detectors: \n",
    "* `cluster-mode` - Clustering algorithm to use _(default=0 i.e. Group Rectangles)_\n",
    "* `interval` - Number of consecutive batches to be skipped for inference _(primary mode only | default=0)_\n",
    "\n",
    "Other optional properties: \n",
    "* `network-mode` - Data format to be used for inference _(0=FP32, 1=INT8, 2=FP16 mode | default=0 i.e. FP32)_\n",
    "* `process-mode` - Mode _(primary or secondary)_ in which the plugin is to operate on _(default=1 i.e. primary)_\n",
    "* `model-color-format` - Color format required by the model _(default=0 i.e. RGB)_\n",
    "* `gie-unique-id` - Unique ID to be assigned to the GIE to enable the application and other elements to identify detected bounding boxes and labels _(default=0)_\n",
    "* `model-engine-file` - Pathname of the serialized model engine file\n",
    "* `gpu-id` - Device ID of GPU to use for pre-processing/inference _(dGPU only)_\n",
    "\n",
    "**Note**: The values in the config file are overridden by values set through GObject properties. Another important thing to remember is that the properties recommended are specific to a primary detector, you will need to work on other properties for secondary and/or classifier. You can find most of the information needed on the [model card](https://catalog.ngc.nvidia.com/orgs/nvidia/models/tlt_dashcamnet): \n",
    "\n",
    "<p><img src='images/model_card.png' width=720></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72dbcf79-4e80-4312-b462-d4aac1ff87e2",
   "metadata": {},
   "source": [
    "**Instructions**: \n",
    "<br>\n",
    "3.1. Open and review the [configuration file](spec_files/pgie_config_dashcamnet.txt). <br>\n",
    "3.2. Update the `<FIXME>`s _only_ in the configuration file with the correct values and **save changes**. Afterwards, make sure in the cell the correct path of the configuration file is referenced and execute the cell to mark your answer. _You can execute this cell multiple times until satisfactory_. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "df8e1e1e-0e46-49a3-9c34-e3f1bccee885",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[property]\n",
      "gpu-id=0\n",
      "net-scale-factor=0.0039215697906911373\n",
      "tlt-model-key=tlt_encode\n",
      "tlt-encoded-model=/dli/task/dashcamnet_vpruned_v1.0/restnet18_dashcamnet_pruned.etlt\n",
      "labelfile-path=/dli/task/dashcamnet_vpruned_v1.0/labels.txt\n",
      "int8-calib-file=/dli/task/dashcamnet_vpruned_v1.0/dashcamnet_int8.txt\n",
      "input-dims=3;720;1280;0\n",
      "uff-input-blob-name=input_1\n",
      "batch-size=1\n",
      "process-mode=1\n",
      "model-color-format=0\n",
      "# 0=FP32, 1=INT8, 2=FP16 mode\n",
      "network-mode=0\n",
      "num-detected-classes=4\n",
      "interval=0\n",
      "gie-unique-id=1\n",
      "output-blob-names=output_bbox/BiasAdd;output_cov/Sigmoid\n",
      "cluster-mode=0\n",
      "'/dli/task/spec_files/pgie_config_dashcamnet.txt' -> 'my_assessment/answer_3.txt'\n"
     ]
    }
   ],
   "source": [
    "# 3.2\n",
    "os.environ['SPEC_FILE']='/dli/task/spec_files/pgie_config_dashcamnet.txt'\n",
    "\n",
    "# DO NOT CHANGE BELOW\n",
    "!cat $SPEC_FILE\n",
    "!cp -v $SPEC_FILE my_assessment/answer_3.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a547a77-8d64-4f83-b26d-91c9ee91edf3",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Step 4: Build and Run DeepStream Pipeline ###\n",
    "Next, it's time to build the pipeline. We're putting the pipeline creation and initiation procedure inside a function so it an be called easily. We also need to implement the probe callback function prior to running the pipeline. We've provided you a functional architecture and framework for this application to follow. Below is the architecture for this pipeline. \n",
    "\n",
    "<p><img src='images/assessment_pipeline.png' width=1080></p>\n",
    "\n",
    "Our logic for determining if a vehicle is tailgating will be based on the coordinates of detected objects' bounding boxes shown below: \n",
    "\n",
    "<p><img src='images/tailgate_metrics.png' width=720></p>\n",
    "\n",
    "While we attached the probe to the _nvdsosd_ plugin, the only requirement is that it has to be after the _nvinfer_ plugin so it contains the AI-infered metadata. Recall that we need to program the probe [callback function](https://en.wikipedia.org/wiki/Callback_(computer_programming)) to provide us a signal when tailgating is potentially occuring. The probe callback function generally follows a boilerplate, to help iterate through the batches, frames, and objects. For more information on how to implement a callback function, please refer to the [GStreamer Probe documentation](https://gstreamer.freedesktop.org/documentation/additional/design/probes.html). \n",
    "\n",
    "<p><img src='images/probe_boiler_plate.png' width=720></p>\n",
    "\n",
    "We want to generate a list that will contain 0s and 1s for each frame to represent if it exhibits tailgating. Therefore there should be as many numbers as there are number of frames in the end. There should _not_ be one number associated with each object detected as it will lead to more than one number associated with each frame. Below is a sample output: \n",
    "\n",
    "<p><img src='images/sample_log.png' width=720></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a860bbe9-b937-47af-a305-95c00d36f580",
   "metadata": {},
   "source": [
    "**Instructions**: \n",
    "<br>\n",
    "4.1. Review the pipeline architecture. <br>\n",
    "4.2. Modify the `<FIXME>` _only_ in the cell with the correct code and execute the cell to define the function that will build and run the pipeline. <br>\n",
    "4.3. Modify the `<FIXME>` _only_ in the cell with the correct code and execute the cell to define the probe callback function. <br>\n",
    "4.4. Execute the cell to run the pipeline. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da9d8b9c-b28b-4d8f-b226-70ca5b76e6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2\n",
    "#Import necessary libraries\n",
    "import sys\n",
    "import gi\n",
    "gi.require_version('Gst', '1.0')\n",
    "from gi.repository import GObject, Gst, GLib\n",
    "from common.bus_call import bus_call\n",
    "import pyds\n",
    "\n",
    "def run(input_file_path):\n",
    "    global inference_output\n",
    "    inference_output=[]\n",
    "    Gst.init(None)\n",
    "\n",
    "    # Create element that will form a pipeline\n",
    "    print(\"Creating Pipeline\")\n",
    "    pipeline=Gst.Pipeline()\n",
    "    \n",
    "    source=Gst.ElementFactory.make('filesrc', \"file-source\")\n",
    "    source.set_property('location', args[1])\n",
    "    h264parser=Gst.ElementFactory.make('h264parse', \"h264-parser\")\n",
    "    decoder=Gst.ElementFactory.make(\"nvv4l2decoder\", \"nvv4l2-decoder\")\n",
    "    \n",
    "    streammux=Gst.ElementFactory.make(<<<<FIXME>>>>, \"Stream-muxer\")    \n",
    "    streammux.set_property('width', <<<<FIXME>>>>)\n",
    "    streammux.set_property('height', <<<<FIXME>>>>)\n",
    "    streammux.set_property('batch-size', <<<<FIXME>>>>)\n",
    "    \n",
    "    pgie=Gst.ElementFactory.make(<<<<FIXME>>>>, \"primary-inference\")\n",
    "    pgie.set_property('config-file-path', os.environ['SPEC_FILE'])\n",
    "    \n",
    "    nvvidconv1=Gst.ElementFactory.make(\"nvvideoconvert\", \"convertor\")\n",
    "    nvosd=Gst.ElementFactory.make(<<<<FIXME>>>>, \"onscreendisplay\")\n",
    "    nvvidconv2=Gst.ElementFactory.make(\"nvvideoconvert\", \"convertor2\")\n",
    "    capsfilter=Gst.ElementFactory.make(\"capsfilter\", \"capsfilter\")\n",
    "    caps=Gst.Caps.from_string(\"video/x-raw, format=I420\")\n",
    "    capsfilter.set_property(\"caps\", caps)\n",
    "    \n",
    "    encoder=Gst.ElementFactory.make(\"avenc_mpeg4\", \"encoder\")\n",
    "    encoder.set_property(\"bitrate\", 2000000)\n",
    "    \n",
    "    sink=Gst.ElementFactory.make(<<<<FIXME>>>>, 'filesink')\n",
    "    sink.set_property('location', 'output.mpeg4')\n",
    "    sink.set_property(\"sync\", 1)\n",
    "    \n",
    "    # Add the elements to the pipeline\n",
    "    print(\"Adding elements to Pipeline\")\n",
    "    pipeline.add(source)\n",
    "    pipeline.add(h264parser)\n",
    "    pipeline.add(decoder)\n",
    "    pipeline.add(streammux)\n",
    "    pipeline.add(<<<<FIXME>>>>)\n",
    "    pipeline.add(nvvidconv1)\n",
    "    pipeline.add(nvosd)\n",
    "    pipeline.add(nvvidconv2)\n",
    "    pipeline.add(capsfilter)\n",
    "    pipeline.add(encoder)\n",
    "    pipeline.add(sink)\n",
    "\n",
    "    # Link the elements together\n",
    "    print(\"Linking elements in the Pipeline\")\n",
    "    source.link(h264parser)\n",
    "    h264parser.link(decoder)\n",
    "    decoder.get_static_pad('src').link(streammux.get_request_pad(\"sink_0\"))\n",
    "    streammux.link(<<<<FIXME>>>>)\n",
    "    <<<<FIXME>>>>.link(nvvidconv1)\n",
    "    nvvidconv1.link(<<<<FIXME>>>>)\n",
    "    <<<<FIXME>>>>.link(nvvidconv2)\n",
    "    nvvidconv2.link(capsfilter)\n",
    "    capsfilter.link(encoder)\n",
    "    encoder.link(sink)\n",
    "    \n",
    "    # Attach probe to OSD sink pad\n",
    "    osdsinkpad=nvosd.get_static_pad(\"sink\")\n",
    "    <<<<FIXME>>>>.add_probe(Gst.PadProbeType.BUFFER, <<<<FIXME>>>>, 0)\n",
    "\n",
    "    # Create an event loop and feed gstreamer bus mesages to it\n",
    "    loop=GLib.MainLoop()\n",
    "    bus=pipeline.get_bus()\n",
    "    bus.add_signal_watch()\n",
    "    bus.connect(\"message\", bus_call, loop)\n",
    "    \n",
    "    # Start play back and listen to events\n",
    "    print(\"Starting pipeline\")\n",
    "    \n",
    "    pipeline.set_state(Gst.State.PLAYING)\n",
    "    try:\n",
    "        loop.run()\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    pipeline.set_state(Gst.State.NULL)\n",
    "    return inference_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d3a5e2-aa96-463a-b9e5-bdf69b48bc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3\n",
    "# Define the Probe Function\n",
    "def osd_sink_pad_buffer_probe(pad, info, u_data):\n",
    "    gst_buffer=info.get_buffer()\n",
    "\n",
    "    # Retrieve batch metadata from the gst_buffer\n",
    "    batch_meta=pyds.gst_buffer_get_nvds_batch_meta(hash(gst_buffer))\n",
    "    l_frame=batch_meta.frame_meta_list\n",
    "    while l_frame is not None:\n",
    "        \n",
    "        # Initially set the tailgate indicator to False for each frame\n",
    "        tailgate=False\n",
    "        try:\n",
    "            frame_meta=pyds.NvDsFrameMeta.cast(l_frame.data)\n",
    "        except StopIteration:\n",
    "            break\n",
    "        frame_number=frame_meta.frame_num\n",
    "        l_obj=frame_meta.obj_meta_list\n",
    "        \n",
    "        # Iterate through each object to check its dimension\n",
    "        while l_obj is not None:\n",
    "            try:\n",
    "                obj_meta=pyds.NvDsObjectMeta.cast(l_obj.data)\n",
    "                \n",
    "                # If the object meet the criteria then set tailgate indicator to True\n",
    "                obj_bottom=obj_meta.rect_params.top+obj_meta.rect_params.height\n",
    "                if (<<<<FIXME>>>> > FRAME_WIDTH*.3) & (<<<<FIXME>>>> > FRAME_HEIGHT*.9): \n",
    "                    tailgate=True\n",
    "                    \n",
    "            except StopIteration:\n",
    "                break\n",
    "            try: \n",
    "                l_obj=l_obj.next\n",
    "            except StopIteration:\n",
    "                break\n",
    "        \n",
    "        print(f'Analyzing frame {frame_number}', end='\\r')\n",
    "        inference_output.append(str(int(<<<<FIXME>>>>)))\n",
    "        try:\n",
    "            l_frame=l_frame.next\n",
    "        except StopIteration:\n",
    "            break\n",
    "    return Gst.PadProbeReturn.OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fef2c16-93b6-4c59-abdc-cd4409cba488",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 4.4\n",
    "tailgate_log=run(input_file_path='/dli/task/data/assessment_stream.h264')\n",
    "\n",
    "# DO NOT CHANGE BELOW\n",
    "with open('/dli/task/my_assessment/answer_4.txt', 'w') as f: \n",
    "    f.write('\\n'.join(tailgate_log))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92642fe5-6bbe-45eb-9ed7-5d4cce4a8a59",
   "metadata": {},
   "source": [
    "## Step 5: Analyze the Results ##\n",
    "Finally, we can analyze the driving behavior using the log we've collected. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11858951-c2bb-4ca1-a921-55f9287fbbd0",
   "metadata": {},
   "source": [
    "**Instructions**: <br>\n",
    "5.1. Execute the cell to import the tailgate log into a Pandas DataFrame. <br>\n",
    "5.2. Execute the cell to plot the occurences of tailgating. <br>\n",
    "5.3. Make sure the output `.mp4` file is being referenced and execute the cell to view the composite with the bounding boxes drawn into the original video. <br>\n",
    "5.4. Execute the cell to calculate the amount of time on average this vehicle spent tailgating. <br>\n",
    "5.5. Modify the `<FIXME>` _only_ to mark your answer. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80436323-269b-4010-8482-167861e93d16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1\n",
    "# DO NOT CHANGE THIS CELL\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('my_assessment/answer_4.txt', names=['inference'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da127db-2687-41c2-a026-8988a4bbe8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2\n",
    "# DO NOT CHANGE THIS CELL\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "df.plot(kind='bar', figsize=(30, 5))\n",
    "plt.xticks(np.arange(0, len(df)+1, FRAME_RATE), np.arange(0, len(df)/FRAME_RATE))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523d15a0-9374-419a-869b-b353fc35de36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.3\n",
    "# DO NOT CHANGE THIS CELL\n",
    "!ffmpeg -i output.mpeg4 output_converted.mp4 \\\n",
    "        -y \\\n",
    "        -loglevel quiet\n",
    "\n",
    "Video('output_converted.mp4', width=720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae0b43f-23e1-4ab9-8fb7-0fec6ac7caaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.4\n",
    "# DO NOT CHANGE THIS CELL\n",
    "display(df['inference'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983d0dc4-9f3c-4396-b4c0-5e52ba303f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question: How much time (without the percentage sign, e.g. 5.0) did the vehicle tailgate? \n",
    "Answer=<<<<FIXME>>>>\n",
    "\n",
    "# EXAMPLE: \n",
    "# Answer='5.0'\n",
    "\n",
    "# DO NOT CHANGE BELOW\n",
    "!echo $Answer > my_assessment/answer_5.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348c075a-6f39-4483-9035-af9ac9f65a5c",
   "metadata": {},
   "source": [
    "## Grade Your Code ##\n",
    "If you have completed all 5 questions and confirmed the pipeline runs correctly, save changes to the notebook and revisit the webpage where you launched this interactive environment. Click on the \"**ASSESS TASK**\" button as shown in the screenshot below. Doing so will give you credit for this part of the lab that counts towards earning a certificate of competency for the entire course. \n",
    "\n",
    "<p><img src='images/credit.png' width=1080></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d2b3429-e152-4ffb-a09d-2945ab3582bc",
   "metadata": {},
   "source": [
    "### BONUS. Visualizing Frames ###\n",
    "Below we have included some helpful functions that will help you visualize the frames that exhibit tailgating behavior. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e0ee86-e27c-48c5-9274-de08cd3aa6fe",
   "metadata": {},
   "source": [
    "**Instructions**: <br>\n",
    "B.1. Execute the cell to extract tailgating frames. <br>\n",
    "B.2. Execute the cell to display randomly selected tailgating frames. <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5967bf7f-4332-4965-b713-c424e62d0dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B.1\n",
    "# DO NOT CHANGE THIS CELL\n",
    "import cv2\n",
    "\n",
    "!mkdir output_images\n",
    "!rm -r output_images/*\n",
    "input_video=cv2.VideoCapture('output_converted.mp4')\n",
    "retVal, im=input_video.read()\n",
    "frameCount=0\n",
    "while retVal:\n",
    "    if frameCount in df[df['inference']==1].index:\n",
    "        cv2.imwrite(\"output_images/frame_%d.jpg\" % frameCount, im)     # save frame as JPEG file      \n",
    "    retVal, im=input_video.read()\n",
    "    print(f'Read a new frame: {frameCount}', end='\\r')\n",
    "    frameCount+=1\n",
    "input_video.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a87a09-d228-4c79-b831-868ebeb58a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# B.2\n",
    "# DO NOT CHANGE THIS CELL\n",
    "from PIL import Image, ImageFont, ImageDraw, ImageEnhance\n",
    "from matplotlib.pyplot import imshow\n",
    "import numpy as np\n",
    "\n",
    "def plot_random_samples(frames):\n",
    "    sample_frames = np.random.choice(frames,size=8)\n",
    "    fig=plt.figure(figsize=(30, 8))\n",
    "    columns = 4\n",
    "    rows = 2\n",
    "    i = 1 \n",
    "    for frame_num in sample_frames:\n",
    "        # im = Image.open('{}/images/{}/{}.jpg'.format(config[\"Base_Dest_Folder\"], config[\"Test_Video_ID\"], box[\"frame_no\"]))\n",
    "        im = Image.open(f'output_images/frame_{frame_num}.jpg')\n",
    "        fig.add_subplot(rows, columns, i)\n",
    "        i += 1\n",
    "        plt.imshow(np.asarray(im))\n",
    "    plt.show()\n",
    "    \n",
    "plot_random_samples(df[df['inference']==1].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b7f52a-c910-4b48-89ee-b241320f0697",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"><img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/></a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
